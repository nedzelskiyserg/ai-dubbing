# -*- coding: utf-8 -*-
import json
import requests
import logging
import re
from typing import List, Dict, Optional, Callable, Any

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logger = logging.getLogger(__name__)

class SpeakerCorrector:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫ –ø—Ä–∏—Å–≤–æ–µ–Ω–∏—è —Å–ø–∏–∫–µ—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é LLM
    –∏ —É–º–Ω–æ–≥–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –¥–ª–∏–Ω—ã.
    """
    
    def __init__(
        self,
        ollama_url: str = "http://localhost:11434",
        model: str = "qwen2.5:7b",
        progress_callback: Optional[Callable[[str], None]] = None
    ):
        self.ollama_url = ollama_url.rstrip('/')
        self.model = model
        self.progress_callback = progress_callback or (lambda msg: None)
    
    def _log(self, message: str):
        """–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        self.progress_callback(message)
        logger.info(message)
    
    def correct(self, segments: List[Dict]) -> List[Dict]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏.
        """
        if not segments:
            self._log("‚ö†Ô∏è –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ - –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–∞")
            return segments
        
        self._log(f"üîß –ù–∞—á–∞–ª–æ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ —Å–ø–∏–∫–µ—Ä–æ–≤: {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        
        # –û–¢–õ–ê–î–ö–ê: –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã—Ö —Å–ø–∏–∫–µ—Ä–æ–≤
        original_speakers = {}
        for i, seg in enumerate(segments):
            speaker = seg.get("speaker", "SPEAKER_UNKNOWN")
            if speaker not in original_speakers:
                original_speakers[speaker] = []
            original_speakers[speaker].append(i)
        
        self._log(f"üìä –ò—Å—Ö–æ–¥–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∏–∫–µ—Ä–æ–≤:")
        for speaker, indices in original_speakers.items():
            self._log(f"   {speaker}: {len(indices)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (ID: {indices[:5]}{'...' if len(indices) > 5 else ''})")
        
        # –®–ê–ì A: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ (ID Mapping)
        segments_with_id = self._prepare_segments(segments)
        
        # –®–ê–ì B: LLM –ö–æ—Ä—Ä–µ–∫—Ü–∏—è
        correction_map = self._llm_correct(segments_with_id)
        
        # –®–ê–ì C: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
        corrected_segments = self._apply_corrections(segments_with_id, correction_map)
        
        # –®–ê–ì D: –£–º–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ (—Å –ª–∏–º–∏—Ç–æ–º –¥–ª–∏–Ω—ã)
        merged_segments = self._smart_merge(corrected_segments)
        
        # –û–¢–õ–ê–î–ö–ê: –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∏–∫–µ—Ä–æ–≤
        final_speakers = {}
        for i, seg in enumerate(merged_segments):
            speaker = seg.get("speaker", "SPEAKER_UNKNOWN")
            if speaker not in final_speakers:
                final_speakers[speaker] = []
            final_speakers[speaker].append(i)
        
        self._log(f"üìä –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∏–∫–µ—Ä–æ–≤:")
        for speaker, indices in final_speakers.items():
            self._log(f"   {speaker}: {len(indices)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        
        self._log(f"‚úÖ –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(merged_segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (–±—ã–ª–æ {len(segments)})")
        
        return merged_segments
    
    def _prepare_segments(self, segments: List[Dict]) -> List[Dict]:
        """–ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–π _id –∏ –ø—Ä–∏–≤–æ–¥–∏—Ç —Ç–∏–ø—ã –∫ float"""
        prepared = []
        for idx, seg in enumerate(segments):
            seg_copy = seg.copy()
            seg_copy['_id'] = idx
            if "start" in seg_copy: seg_copy["start"] = float(seg_copy["start"])
            if "end" in seg_copy: seg_copy["end"] = float(seg_copy["end"])
            prepared.append(seg_copy)
        return prepared
    
    def _llm_correct(self, segments_with_id: List[Dict]) -> Dict[int, str]:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã –≤ LLM –∏ –ø–æ–ª—É—á–∞–µ—Ç –º–∞–ø–ø–∏–Ω–≥ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π"""
        
        # –£–ø—Ä–æ—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤, –Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç (–ø—Ä–µ–¥—ã–¥—É—â–∏–π –∏ —Å–ª–µ–¥—É—é—â–∏–π —Å–µ–≥–º–µ–Ω—Ç)
        simplified = []
        for idx, seg in enumerate(segments_with_id):
            seg_data = {
                "id": seg["_id"],  # LLM –ª—É—á—à–µ –ø–æ–Ω–∏–º–∞–µ—Ç "id" —á–µ–º "_id"
                "text": seg.get("text", ""),
                "speaker": seg.get("speaker", "SPEAKER_UNKNOWN")
            }
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–π
            if idx > 0:
                prev_text = segments_with_id[idx - 1].get("text", "")
                seg_data["prev_text"] = prev_text[-50:] if len(prev_text) > 50 else prev_text  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 50 —Å–∏–º–≤–æ–ª–æ–≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ
            if idx < len(segments_with_id) - 1:
                next_text = segments_with_id[idx + 1].get("text", "")
                seg_data["next_text"] = next_text[:50] if len(next_text) > 50 else next_text  # –ü–µ—Ä–≤—ã–µ 50 —Å–∏–º–≤–æ–ª–æ–≤ —Å–ª–µ–¥—É—é—â–µ–≥–æ
            simplified.append(seg_data)
        
        system_prompt = (
            "You are an Expert Dialogue Diarization AI. Your goal is to reconstruct the perfect conversation flow by assigning the correct speaker to each text segment based on DEEP SEMANTIC ANALYSIS.\n\n"
            
            "### CORE MISSION\n"
            "The input is a list of 'chopped' audio segments. They may be split mid-sentence or contain rapid exchanges. "
            "You must identify WHO is speaking by analyzing the context, logic, and grammar of the dialogue.\n\n"
            
            "### CRITICAL RULE #1: GRAMMATICAL CONTINUITY (HIGHEST PRIORITY)\n"
            "If a sentence is split across multiple segments, they MUST have the SAME speaker. This is NON-NEGOTIABLE.\n\n"
            "**How to detect grammatical continuity:**\n"
            "- If Segment N ends with a COMMA [,] and Segment N+1 starts with a lowercase letter, preposition, conjunction, or continues the thought grammatically, "
            "  they are ONE sentence and MUST have the SAME speaker.\n"
            "- If Segment N ends with an INCOMPLETE CONJUNCTION/PREPOSITION (e.g., '–ê –µ—â–µ', '–ò –µ—â–µ', '–ù–æ', '–ê', '–ò', '–í', '–ù–∞') "
            "  without punctuation, and Segment N+1 starts with a lowercase letter, they are ONE sentence and MUST have the SAME speaker.\n"
            "- Example 1: '–≥–æ–≤–æ—Ä—è—Ç –Ω–∞—Å, –ª—é–¥–∏ –±–µ–¥–Ω—ã–µ' (ends with comma) + '—Ö–ª–µ–± –±–µ–∑ —Å–æ–ª–∏ –¥–æ–µ–¥–∞—é—Ç' (starts lowercase) = ONE sentence = ONE speaker.\n"
            "- Example 2: '–ê –µ—â–µ' (ends with conjunction) + '–≥–æ–≤–æ—Ä—è—Ç –Ω–∞—Å, –ª—é–¥–∏ –±–µ–¥–Ω—ã–µ' (starts lowercase) = ONE sentence = ONE speaker.\n"
            "- The speaker of the FIRST part (ending with comma/conjunction) is the CORRECT speaker for BOTH parts.\n"
            "- If you see this pattern, assign the SAME speaker to both segments, using the speaker from the segment that ENDS with comma/conjunction.\n"
            "- IMPORTANT: Even if there is a large time gap between segments, if they are grammatically connected, they MUST have the SAME speaker.\n\n"
            
            "### ANALYSIS RULES (Follow strictly):\n"
            "1. **Semantic Continuity - CRITICAL**: If a sentence is split across multiple segments, they MUST have the SAME speaker. "
            "   - If Segment N ends with a COMMA [,] and Segment N+1 continues grammatically (e.g., '–≥–æ–≤–æ—Ä—è—Ç –Ω–∞—Å, –ª—é–¥–∏ –±–µ–¥–Ω—ã–µ' ‚Üí '—Ö–ª–µ–± –±–µ–∑ —Å–æ–ª–∏ –¥–æ–µ–¥–∞—é—Ç'), "
            "     they are ONE sentence and MUST have the SAME speaker. This is NON-NEGOTIABLE.\n"
            "   - If Segment N ends with an INCOMPLETE CONJUNCTION/PREPOSITION without punctuation (e.g., '–ê –µ—â–µ', '–ò –µ—â–µ', '–ù–æ', '–ê', '–ò', '–í', '–ù–∞'), "
            "     and Segment N+1 starts with a lowercase letter, they are ONE sentence and MUST have the SAME speaker.\n"
            "   - Example 1: '–≥–æ–≤–æ—Ä—è—Ç –Ω–∞—Å, –ª—é–¥–∏ –±–µ–¥–Ω—ã–µ' (SPEAKER_01) + '—Ö–ª–µ–± –±–µ–∑ —Å–æ–ª–∏ –¥–æ–µ–¥–∞—é—Ç' (SPEAKER_00) ‚Üí BOTH should be SPEAKER_01.\n"
            "   - Example 2: '–ê –µ—â–µ' (SPEAKER_00) + '–≥–æ–≤–æ—Ä—è—Ç –Ω–∞—Å, –ª—é–¥–∏ –±–µ–¥–Ω—ã–µ' (SPEAKER_01) ‚Üí BOTH should be SPEAKER_00 (the one who started with '–ê –µ—â–µ').\n"
            "   - Look for grammatical incompleteness: segment ends with adjective/comma/conjunction ‚Üí next starts with noun/verb/lowercase = continuation = SAME speaker.\n"
            "   - If Segment N ends with a comma or incomplete conjunction and Segment N+1 starts with a lowercase letter, preposition, conjunction, or continues the thought grammatically, "
            "     it's DEFINITELY the SAME speaker. Do NOT assign different speakers to parts of one sentence.\n"
            "   - **IMPORTANT**: When you detect this pattern, use the speaker from the segment that ENDS with comma/conjunction as the correct speaker for BOTH segments.\n"
            "   - **CRITICAL**: Even if there is a large time gap between segments, if they are grammatically connected, they MUST have the SAME speaker.\n"
            "2. **Q&A Logic - CRITICAL**: If Segment N ends with a QUESTION [?] and Segment N+1 is an ANSWER (especially starting with a number, 'Yes', 'No', or a direct response), "
            "   they likely belong to DIFFERENT speakers. Example: 'How much do you make? 72 thousand.' ‚Üí Question (Speaker A) + Answer (Speaker B).\n"
            "   - Exception: Rhetorical questions or self-corrections belong to the SAME speaker.\n"
            "   - IMPORTANT: Distinguish between comma (continuation) and question mark (potential speaker change).\n"
            "3. **Short Reactions**: Words like 'Yes', 'No', 'Exactly', 'What?', 'Really?' usually belong to the LISTENER (change of speaker), "
            "   UNLESS they are part of a continuous monologue (e.g., 'I went there. Yes, I did.').\n"
            "4. **Interruptions & Emotional Outbursts**: If Segment N ends with an interruption, emotional outburst, or sudden cutoff, "
            "   and Segment N+1 is a reaction or response, CHANGE the speaker. Example: 'Show me your ID!' ‚Üí 'Yes, of course.' = different speakers.\n"
            "5. **Dialogue vs Monologue**: Detect if a speaker is telling a story. In a story, even if they quote someone else, the SPEAKER label usually remains the narrator, "
            "   UNLESS the context implies an interruption or response from another character.\n"
            "6. **Speaker Consistency**: Minimize unnecessary speaker switches. If it's ambiguous, assume the current speaker continues.\n"
            "7. **Number Responses**: If a segment starts with a number (e.g., '72 thousand', '22 million') and follows a question, "
            "   it is almost ALWAYS a response from a DIFFERENT speaker answering the question.\n\n"
            
            "### INPUT FORMAT\n"
            "Each segment may include 'prev_text' (previous segment ending) and 'next_text' (next segment beginning) for context.\n"
            "Use this context to detect grammatical continuity. If 'prev_text' ends with comma and current 'text' starts lowercase, "
            "they are ONE sentence = SAME speaker (use the speaker from the segment with comma).\n\n"
            
            "### OUTPUT FORMAT\n"
            "Return a strictly valid JSON LIST of objects with 'id' and 'speaker'. "
            "Example:\n"
            "[{\"id\": 0, \"speaker\": \"SPEAKER_00\"}, {\"id\": 1, \"speaker\": \"SPEAKER_01\"}, {\"id\": 2, \"speaker\": \"SPEAKER_00\"}]\n"
            "CRITICAL: The output list MUST contain exactly the same number of items as the input. Return ALL segments.\n"
            "CRITICAL: When you detect grammatical continuity (comma + lowercase continuation), assign the SAME speaker to both segments, using the speaker from the segment that ENDS with comma.\n"
            "CRITICAL: Analyze the 'prev_text' and 'next_text' fields to understand context and detect split sentences."
        )
        
        self._log(f"üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ {len(simplified)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ LLM")
        
        # –û–¢–õ–ê–î–ö–ê: –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏ –∏—â–µ–º –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è
        if len(simplified) > 0:
            preview = simplified[:5]
            self._log(f"üìã –ü—Ä–∏–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–ø–µ—Ä–≤—ã–µ 5):")
            for seg in preview:
                text_preview = seg['text'][:60] + "..." if len(seg['text']) > 60 else seg['text']
                context_info = ""
                if 'prev_text' in seg:
                    context_info += f" [prev: ...{seg['prev_text'][-20:]}]"
                if 'next_text' in seg:
                    context_info += f" [next: {seg['next_text'][:20]}...]"
                self._log(f"   ID {seg['id']}: [{seg['speaker']}] {text_preview}{context_info}")
            
            # –ò—â–µ–º –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            for i in range(len(simplified) - 1):
                current = simplified[i]
                next_seg = simplified[i + 1]
                current_text = current.get('text', '').strip()
                next_text = next_seg.get('text', '').strip()
                
                if current_text.endswith(',') and next_text and next_text[0].islower():
                    self._log(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ: ID {current['id']} (ends with ',') ‚Üí ID {next_seg['id']} (starts lowercase)")
                    self._log(f"   –¢–µ–∫—É—â–∏–µ —Å–ø–∏–∫–µ—Ä—ã: {current['speaker']} ‚Üí {next_seg['speaker']}")
                    if current['speaker'] != next_seg['speaker']:
                        self._log(f"   ‚ùå –†–ê–ó–ù–´–ï —Å–ø–∏–∫–µ—Ä—ã! LLM –¥–æ–ª–∂–µ–Ω –∏—Å–ø—Ä–∞–≤–∏—Ç—å —ç—Ç–æ!")
        
        try:
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json={
                    "model": self.model,
                    "system": system_prompt,
                    "prompt": json.dumps(simplified, ensure_ascii=False),
                    "stream": False,
                    "options": {"temperature": 0.1}
                },
                timeout=120
            )
            
            if response.status_code != 200:
                self._log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Ollama: {response.status_code}")
                return {}

            response_text = response.json().get("response", "").strip()
            
            # –û–¢–õ–ê–î–ö–ê: –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç
            self._log(f"üì• –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç LLM (–¥–ª–∏–Ω–∞: {len(response_text)} —Å–∏–º–≤–æ–ª–æ–≤)")
            if len(response_text) > 0:
                preview_response = response_text[:500] if len(response_text) > 500 else response_text
                self._log(f"üìÑ –ù–∞—á–∞–ª–æ –æ—Ç–≤–µ—Ç–∞: {preview_response}...")
            
            # –ß–∏—Å—Ç–∫–∞ –æ—Ç Markdown
            if "```" in response_text:
                response_text = response_text.replace("```json", "").replace("```", "").strip()
            
            # –ü–∞—Ä—Å–∏–Ω–≥ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
            data = None
            try:
                data = json.loads(response_text)
                self._log(f"üîç –†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ: {type(data).__name__}")
            except json.JSONDecodeError as e:
                self._log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
                
                # –ü–æ–ø—ã—Ç–∫–∞ 1: –ò—Å–ø—Ä–∞–≤–∏—Ç—å —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ LLM
                fixed_text = response_text
                
                # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –¥–≤–æ–π–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –≤ –∫–ª—é—á–∞—Ö: {"id": 1": 10} ‚Üí {"id": 10}
                fixed_text = re.sub(r'"id":\s*(\d+)"\s*:\s*(\d+)', r'"id": \2', fixed_text)
                
                # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ª–∏—à–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏: "id": "0" ‚Üí "id": 0
                fixed_text = re.sub(r'"id":\s*"(\d+)"', r'"id": \1', fixed_text)
                
                # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∑–∞–ø—è—Ç—ã—Ö –º–µ–∂–¥—É –æ–±—ä–µ–∫—Ç–∞–º–∏
                fixed_text = re.sub(r'}\s*{', r'}, {', fixed_text)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É, –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
                if not fixed_text.rstrip().endswith("]"):
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Å–ø–∏—Å–æ–∫
                    if fixed_text.strip().startswith("["):
                        fixed_text = fixed_text.rstrip() + "]"
                
                try:
                    data = json.loads(fixed_text)
                    self._log(f"‚úÖ JSON –∏—Å–ø—Ä–∞–≤–ª–µ–Ω –∏ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω")
                except Exception as e2:
                    self._log(f"‚ö†Ô∏è –ü–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å: {e2}")
                    
                    # –ü–æ–ø—ã—Ç–∫–∞ 2: –ò–∑–≤–ª–µ—á—å –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã —Å –ø–æ–º–æ—â—å—é regex
                    try:
                        # –ò—â–µ–º –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã –≤–∏–¥–∞ {"id": X, "speaker": "Y"}
                        pattern = r'\{"id"\s*:\s*(\d+)\s*,\s*"speaker"\s*:\s*"([^"]+)"\}'
                        matches = re.findall(pattern, fixed_text)
                        
                        if matches:
                            data = [{"id": int(m[0]), "speaker": m[1]} for m in matches]
                            self._log(f"‚úÖ JSON –∏–∑–≤–ª–µ—á–µ–Ω —á–µ—Ä–µ–∑ regex: –Ω–∞–π–¥–µ–Ω–æ {len(data)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
                        else:
                            raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π")
                    except Exception as e3:
                        self._log(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç LLM –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫: {e3}")
                        self._log(f"üìÑ –ü—Ä–æ–±–ª–µ–º–Ω—ã–π —Ç–µ–∫—Å—Ç (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {response_text[:500]}...")
                        return {}

            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ map {id: speaker}
            result_map = {}
            if isinstance(data, list):
                for item in data:
                    if "id" in item and "speaker" in item:
                        result_map[item["id"]] = item["speaker"]
            
            # –û–¢–õ–ê–î–ö–ê: –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            self._log(f"üì• LLM –≤–µ—Ä–Ω—É–ª {len(result_map)}/{len(simplified)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
            
            if len(result_map) < len(simplified):
                missing = len(simplified) - len(result_map)
                self._log(f"‚ö†Ô∏è LLM –Ω–µ –≤–µ—Ä–Ω—É–ª {missing} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ - –æ–Ω–∏ –æ—Å—Ç–∞–Ω—É—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
            if result_map:
                changes_examples = []
                for seg_id, new_speaker in list(result_map.items())[:5]:  # –ü–µ—Ä–≤—ã–µ 5
                    if seg_id < len(segments_with_id):
                        old_speaker = segments_with_id[seg_id].get("speaker", "UNKNOWN")
                        if old_speaker != new_speaker:
                            changes_examples.append(f"ID {seg_id}: {old_speaker} ‚Üí {new_speaker}")
                
                if changes_examples:
                    self._log(f"üìã –ü—Ä–∏–º–µ—Ä—ã –∏–∑–º–µ–Ω–µ–Ω–∏–π: {', '.join(changes_examples)}")
                else:
                    self._log(f"‚ÑπÔ∏è LLM –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª —Ç–µ–∫—É—â–∏—Ö —Å–ø–∏–∫–µ—Ä–æ–≤ (–∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ—Ç)")
            
            return result_map

        except Exception as e:
            self._log(f"‚ùå –°–±–æ–π –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {e}")
            return {}

    def _apply_corrections(self, segments: List[Dict], correction_map: Dict[int, str]) -> List[Dict]:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è, –Ω–µ —Ç—Ä–æ–≥–∞—è —Ç–∞–π–º–∏–Ω–≥–∏"""
        corrected = []
        changes = 0
        applied = 0
        not_found = 0
        
        for seg in segments:
            seg_copy = seg.copy()
            seg_id = seg_copy.get("_id")
            old_speaker = seg_copy.get("speaker", "SPEAKER_UNKNOWN")
            
            if seg_id in correction_map:
                new_speaker = correction_map[seg_id]
                applied += 1
                if new_speaker != old_speaker:
                    seg_copy["speaker"] = new_speaker
                    changes += 1
                    self._log(f"üîÑ –°–µ–≥–º–µ–Ω—Ç {seg_id}: {old_speaker} ‚Üí {new_speaker}")
            else:
                not_found += 1
                # LLM –Ω–µ –≤–µ—Ä–Ω—É–ª —ç—Ç–æ—Ç —Å–µ–≥–º–µ–Ω—Ç - –æ—Å—Ç–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏–∫–µ—Ä
            
            if "_id" in seg_copy: del seg_copy["_id"] # –ß–∏—Å—Ç–∏–º –º—É—Å–æ—Ä
            corrected.append(seg_copy)
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self._log(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è: –ø—Ä–∏–º–µ–Ω–µ–Ω–æ {applied}/{len(segments)}, –∏–∑–º–µ–Ω–µ–Ω–æ {changes}, –Ω–µ –Ω–∞–π–¥–µ–Ω–æ {not_found}")
        
        if changes == 0 and applied > 0:
            self._log(f"‚ÑπÔ∏è LLM –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª –≤—Å–µ—Ö —Å–ø–∏–∫–µ—Ä–æ–≤ (–∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è)")
        elif changes == 0 and applied == 0:
            self._log(f"‚ö†Ô∏è LLM –Ω–µ –≤–µ—Ä–Ω—É–ª –Ω–∏ –æ–¥–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –Ω–µ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã")
        
        return corrected

    def _smart_merge(self, segments: List[Dict]) -> List[Dict]:
        """
        –£–º–Ω–∞—è —Å–∫–ª–µ–π–∫–∞: –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å–æ—Å–µ–¥–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã –æ–¥–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞,
        –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç SPEAKER_UNKNOWN, —É—Å—Ç—Ä–∞–Ω—è–µ—Ç –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è —Ç–∞–π–º–∏–Ω–≥–æ–≤.
        """
        if not segments: return []

        # –®–ê–ì 1: –ò—Å–ø—Ä–∞–≤–ª—è–µ–º SPEAKER_UNKNOWN (–∑–∞–º–µ–Ω—è–µ–º –Ω–∞ –±–ª–∏–∂–∞–π—à–µ–≥–æ —Å–ø–∏–∫–µ—Ä–∞)
        segments = self._fix_unknown_speakers(segments)
        
        # –®–ê–ì 2: –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–µ—Å—è —Ç–∞–π–º–∏–Ω–≥–∏
        segments = self._fix_overlapping_timestamps(segments)

        merged = []
        current = segments[0].copy()
        
        # –õ–∏–º–∏—Ç—ã
        MAX_MERGE_DURATION = 8.0  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 8 —Å–µ–∫ –¥–ª—è –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑
        MAX_GAP = 1.5             # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 1.5 —Å–µ–∫ –¥–ª—è —Å–∫–ª–µ–π–∫–∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑

        for next_seg in segments[1:]:
            current_start = float(current['start'])
            current_end = float(current['end'])
            next_start = float(next_seg['start'])
            next_end = float(next_seg['end'])
            
            # –í—ã—á–∏—Å–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π —Å–∫–ª–µ–π–∫–∏
            potential_duration = next_end - current_start
            gap = next_start - current_end
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫—É—é —Å–≤—è–∑–Ω–æ—Å—Ç—å
            current_text = current.get('text', '').strip()
            next_text = next_seg.get('text', '').strip()
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ï—Å–ª–∏ —Ç–µ–∫—É—â–∏–π —Å–µ–≥–º–µ–Ω—Ç –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ –∑–∞–ø—è—Ç—É—é, –∞ —Å–ª–µ–¥—É—é—â–∏–π –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏
            # - —ç—Ç–æ –û–î–ù–û –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, —Ä–∞–∑–±–∏—Ç–æ–µ –ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ = –û–î–ò–ù —Å–ø–∏–∫–µ—Ä
            ends_with_comma = current_text.endswith(',') or current_text.endswith('Ôºå')  # –ó–∞–ø—è—Ç–∞—è –∏–ª–∏ –∫–∏—Ç–∞–π—Å–∫–∞—è –∑–∞–ø—è—Ç–∞—è
            
            # –ù–û–í–û–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (—Å–µ–≥–º–µ–Ω—Ç –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ —Å–æ—é–∑/–ø—Ä–µ–¥–ª–æ–≥ –±–µ–∑ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏)
            # –ù–û: –ë—É–¥–µ–º –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã - "–ê –µ—â–µ" –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∞—á–∞–ª–æ–º –Ω–æ–≤–æ–π –º—ã—Å–ª–∏ –¥—Ä—É–≥–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞
            current_text_lower = current_text.lower().strip()
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–µ—Ä–µ–¥ "–ê –µ—â–µ" / "–ò –µ—â–µ" —Ç–æ—á–∫–∞ –∏–ª–∏ –¥—Ä—É–≥–æ–π –∑–Ω–∞–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            # –ï—Å–ª–∏ –µ—Å—Ç—å - —ç—Ç–æ –ù–ï –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ, –∞ –Ω–æ–≤–∞—è –º—ã—Å–ª—å
            has_sentence_end_before = bool(re.search(
                r'[.!?]\s+(–∞\s+–µ—â–µ|–∏\s+–µ—â–µ|–Ω–æ\s+–ø—Ä–∏|–∞\s+–≤–æ—Ç|–∏\s+–≤–æ—Ç)\s*$',
                current_text_lower
            ))
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –ó–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ —Å–æ—é–∑/–ø—Ä–µ–¥–ª–æ–≥ –±–µ–∑ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ (–Ω–æ –Ω–µ –ø–æ—Å–ª–µ —Ç–æ—á–∫–∏)
            ends_with_single_conjunction = bool(re.search(
                r'\s+(–∞|–∏|–Ω–æ|–¥–∞|–≤|–Ω–∞|—Å|–∫|–æ—Ç|–¥–æ|–∑–∞|–ø–æ|–ø–æ–¥|–Ω–∞–¥|–ø—Ä–∏|–ø—Ä–æ|–±–µ–∑|–¥–ª—è|–∏–∑|–æ|–æ–±|—É|—Å–æ|–≤–æ|—á—Ç–æ|–∫–æ—Ç–æ—Ä—ã–π|–≥–¥–µ|–∫–æ–≥–¥–∞)\s*$',
                current_text_lower
            )) and not has_sentence_end_before
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –ó–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ —Ñ—Ä–∞–∑—ã —Ç–∏–ø–∞ "–ê –µ—â–µ", "–ò –µ—â–µ" (–Ω–æ –Ω–µ –ø–æ—Å–ª–µ —Ç–æ—á–∫–∏)
            ends_with_phrase = bool(re.search(
                r'(–∞\s+–µ—â–µ|–∏\s+–µ—â–µ|–Ω–æ\s+–ø—Ä–∏|–∞\s+–≤–æ—Ç|–∏\s+–≤–æ—Ç|–∞\s+–≤–æ—Ç\s+–µ—â–µ|–∏\s+–≤–æ—Ç\s+–µ—â–µ|–∞\s+–ø–æ—Ç–æ–º|–∏\s+–ø–æ—Ç–æ–º|–∞\s+—Ç–µ–ø–µ—Ä—å|–∏\s+—Ç–µ–ø–µ—Ä—å)\s*$',
                current_text_lower
            )) and not has_sentence_end_before
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ 3: –ó–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ "–µ—â–µ" (–Ω–æ –Ω–µ –ø–æ—Å–ª–µ —Ç–æ—á–∫–∏)
            ends_with_–µ—â–µ = (current_text_lower.endswith('–µ—â–µ') or current_text_lower.endswith('–µ—â—ë')) and not has_sentence_end_before
            
            ends_with_incomplete = ends_with_single_conjunction or ends_with_phrase or ends_with_–µ—â–µ
            
            # –û–¢–õ–ê–î–ö–ê: –ï—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏ "–ê –µ—â–µ" –ø–æ—Å–ª–µ —Ç–æ—á–∫–∏ - —ç—Ç–æ –ù–ï –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ
            if has_sentence_end_before:
                self._log(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ '–ê –µ—â–µ' –ø–æ—Å–ª–µ —Ç–æ—á–∫–∏ - —ç—Ç–æ –ù–ï –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ, –∞ –Ω–æ–≤–∞—è –º—ã—Å–ª—å: '{current_text[-50:]}'")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ
            if next_text and len(next_text) > 0:
                next_first_char = next_text[0]
                next_starts_lowercase = next_first_char.islower()  # –° –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä—É—Å—Å–∫–∏–µ –±—É–∫–≤—ã (–º–∞–ª–µ–Ω—å–∫–∏–µ)
                next_starts_russian_lowercase = bool(re.search(r'^[–∞-—è—ë]', next_text))
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—é–∑—ã/–º–µ—Å—Ç–æ–∏–º–µ–Ω–∏—è/–ø—Ä–µ–¥–ª–æ–≥–∏
                next_starts_with_connector = bool(re.search(
                    r'^(–∏|–∞|–Ω–æ|–¥–∞|–Ω–µ—Ç|—á—Ç–æ|–∫–æ—Ç–æ—Ä—ã–π|–≥–¥–µ|–∫–æ–≥–¥–∞|–≤|–Ω–∞|—Å|–∫|–æ—Ç|–¥–æ|–∑–∞|–ø–æ|–ø–æ–¥|–Ω–∞–¥|–ø—Ä–∏|–ø—Ä–æ|–±–µ–∑|–¥–ª—è|–∏–∑|–æ|–æ–±|—É|—Å–æ|–≤–æ)',
                    next_text.lower()
                ))
            else:
                next_starts_lowercase = False
                next_starts_russian_lowercase = False
                next_starts_with_connector = False
            
            # –ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ: 
            # 1. –ó–∞–ø—è—Ç–∞—è + –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ (–º–∞–ª–µ–Ω—å–∫–∞—è –±—É–∫–≤–∞ –∏–ª–∏ —Å–æ—é–∑/–º–µ—Å—Ç–æ–∏–º–µ–Ω–∏–µ)
            # 2. –ù–ï–ó–ê–í–ï–†–®–ï–ù–ù–û–ï –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ (—Å–æ—é–∑/–ø—Ä–µ–¥–ª–æ–≥ –±–µ–∑ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏) + –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ
            # –ù–û: "–ê –µ—â–µ" –ø–æ—Å–ª–µ —Ç–æ—á–∫–∏ - —ç—Ç–æ –ù–ï –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ, –∞ –Ω–æ–≤–∞—è –º—ã—Å–ª—å
            next_continues_grammatically = (
                (ends_with_comma and (
                    next_starts_lowercase or 
                    next_starts_russian_lowercase or
                    next_starts_with_connector
                )) or
                (ends_with_incomplete and not has_sentence_end_before and (
                    next_starts_lowercase or 
                    next_starts_russian_lowercase
                ))
            )
            
            # –û–¢–õ–ê–î–ö–ê: –õ–æ–≥–∏—Ä—É–µ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
            if ends_with_incomplete and not ends_with_comma:
                self._log(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: '{current_text[-50:]}'")
                self._log(f"   ‚Üí –°–ª–µ–¥—É—é—â–∏–π —Å–µ–≥–º–µ–Ω—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è: '{next_text[:30]}...' (lowercase: {next_starts_lowercase}, russian: {next_starts_russian_lowercase})")
                self._log(f"   ‚Üí –ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ: {next_continues_grammatically}, gap: {gap:.1f}s")
            
            # –£–°–õ–û–í–ò–Ø –û–ë–™–ï–î–ò–ù–ï–ù–ò–Ø:
            # 1. –¢–æ—Ç –∂–µ —Å–ø–∏–∫–µ—Ä –ò–õ–ò –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ (–∑–∞–ø—è—Ç–∞—è + –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ = –æ–¥–∏–Ω —Å–ø–∏–∫–µ—Ä)
            # 2. –ú–∞–ª–µ–Ω—å–∫–∞—è –ø–∞—É–∑–∞ –∏–ª–∏ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ (–ù–û –¥–ª—è –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –±–æ–ª—å—à–æ–π gap)
            # 3. –ù–µ –ø—Ä–µ–≤—ã—à–∞–µ–º –ª–∏–º–∏—Ç –¥–ª–∏–Ω—ã
            same_speaker = current['speaker'] == next_seg['speaker']
            is_grammatical_continuation = next_continues_grammatically  # –ó–∞–ø—è—Ç–∞—è + –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ = –æ–¥–∏–Ω —Å–ø–∏–∫–µ—Ä
            
            # –í–ê–ñ–ù–û: –î–ª—è –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –±–æ–ª—å—à–æ–π gap
            # –ù–û: –î–ª—è –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (–æ—Å–æ–±–µ–Ω–Ω–æ "–ê –µ—â–µ" –ø–æ—Å–ª–µ —Ç–æ—á–∫–∏) –±—É–¥–µ–º –æ—Å—Ç–æ—Ä–æ–∂–Ω–µ–µ
            if is_grammatical_continuation:
                if ends_with_incomplete:
                    # –ù–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ - –æ–±—ä–µ–¥–∏–Ω—è–µ–º, –Ω–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º gap (10 —Å–µ–∫)
                    # –ï—Å–ª–∏ "–ê –µ—â–µ" –ø–æ—Å–ª–µ —Ç–æ—á–∫–∏, —Ç–æ ends_with_incomplete —É–∂–µ –±—É–¥–µ—Ç False, —Ç–∞–∫ —á—Ç–æ –∑–¥–µ—Å—å —Ç–æ–ª—å–∫–æ –Ω–∞—Å—Ç–æ—è—â–∏–µ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ
                    max_gap_for_incomplete = 10.0  # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –ª–∏–º–∏—Ç –¥–ª—è –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
                    gap_acceptable = gap < max_gap_for_incomplete
                    self._log(f"   ‚ÑπÔ∏è –ù–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ - –æ–±—ä–µ–¥–∏–Ω—è–µ–º –ø—Ä–∏ gap < {max_gap_for_incomplete}s (—Ç–µ–∫—É—â–∏–π: {gap:.1f}s)")
                else:
                    # –ó–∞–ø—è—Ç–∞—è + –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ - –æ–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–∂–µ –ø—Ä–∏ –±–æ–ª—å—à–æ–º gap (30 —Å–µ–∫)
                    small_gap = True  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º gap –¥–ª—è –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö
                    max_gap_for_grammatical = 30.0  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π gap –¥–ª—è –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                    gap_acceptable = gap < max_gap_for_grammatical
            else:
                small_gap = gap < MAX_GAP or gap < 0  # –†–∞–∑—Ä–µ—à–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–µ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ
                gap_acceptable = True
            
            within_limit = potential_duration < MAX_MERGE_DURATION
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –µ—Å–ª–∏: —Ç–æ—Ç –∂–µ —Å–ø–∏–∫–µ—Ä –ò–õ–ò –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ (–∑–∞–ø—è—Ç–∞—è/–Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–µ)
            if (same_speaker or is_grammatical_continuation) and gap_acceptable and within_limit:
                # –ï—Å–ª–∏ —ç—Ç–æ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ, –Ω–æ —Å–ø–∏–∫–µ—Ä—ã —Ä–∞–∑–Ω—ã–µ - –∏—Å–ø—Ä–∞–≤–ª—è–µ–º —Å–ø–∏–∫–µ—Ä–∞
                if is_grammatical_continuation and not same_speaker:
                    # –≠—Ç–æ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, —Ä–∞–∑–±–∏—Ç–æ–µ –ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ - –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ–¥–∏–Ω —Å–ø–∏–∫–µ—Ä
                    # –í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–∏–∫–µ—Ä–∞ —Å–µ–≥–º–µ–Ω—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ –∑–∞–ø—è—Ç—É—é/—Å–æ—é–∑ (–Ω–∞—á–∞–ª–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
                    old_speaker_next = next_seg['speaker']
                    old_speaker_current = current['speaker']
                    correct_speaker = current['speaker']  # –°–µ–≥–º–µ–Ω—Ç —Å –∑–∞–ø—è—Ç–æ–π/—Å–æ—é–∑–æ–º = –Ω–∞—á–∞–ª–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                    
                    # –ò–°–ü–†–ê–í–õ–Ø–ï–ú: –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞ –û–ë–û–ò–ú —Å–µ–≥–º–µ–Ω—Ç–∞–º –î–û –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
                    current['speaker'] = correct_speaker
                    next_seg['speaker'] = correct_speaker
                    
                    gap_info = f" (gap: {gap:.1f}s)" if gap > 0 else ""
                    self._log(f"üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ{gap_info}: '{current_text[-40:]}' + '{next_text[:40]}'")
                    self._log(f"   üìù –ù–∞—á–∞–ª–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è [{old_speaker_current}] ‚Üí [{correct_speaker}]")
                    self._log(f"   üìù –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ [{old_speaker_next}] ‚Üí [{correct_speaker}]")
                
                # –ö–ª–µ–∏–º! (—Ç–µ–ø–µ—Ä—å current —É–∂–µ –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞)
                current['end'] = max(current_end, next_end)  # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π end
                current['text'] = (current_text + " " + next_text).strip()
                if 'words' in current and 'words' in next_seg:
                    current['words'].extend(next_seg['words'])
                self._log(f"   ‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ –≤ –æ–¥–∏–Ω —Å–µ–≥–º–µ–Ω—Ç: [{current['speaker']}] '{current['text'][:60]}...'")
            else:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π
                merged.append(current)
                current = next_seg.copy()

        merged.append(current)
        
        if len(merged) < len(segments):
            self._log(f"üîó –°–∫–ª–µ–µ–Ω–æ: {len(segments)} ‚Üí {len(merged)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        
        return merged
    
    def _fix_unknown_speakers(self, segments: List[Dict]) -> List[Dict]:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç SPEAKER_UNKNOWN, –∑–∞–º–µ–Ω—è—è –Ω–∞ –±–ª–∏–∂–∞–π—à–µ–≥–æ —Å–ø–∏–∫–µ—Ä–∞"""
        if not segments:
            return segments
        
        fixed = []
        known_speakers = set()
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ—Ö –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Å–ø–∏–∫–µ—Ä–æ–≤
        for seg in segments:
            speaker = seg.get('speaker', 'SPEAKER_UNKNOWN')
            if speaker != 'SPEAKER_UNKNOWN':
                known_speakers.add(speaker)
        
        if not known_speakers:
            # –ï—Å–ª–∏ –Ω–µ—Ç –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Å–ø–∏–∫–µ—Ä–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º SPEAKER_00 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            known_speakers.add('SPEAKER_00')
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º SPEAKER_UNKNOWN
        for i, seg in enumerate(segments):
            seg_copy = seg.copy()
            speaker = seg_copy.get('speaker', 'SPEAKER_UNKNOWN')
            
            if speaker == 'SPEAKER_UNKNOWN':
                # –ò—â–µ–º –±–ª–∏–∂–∞–π—à–µ–≥–æ —Å–ø–∏–∫–µ—Ä–∞ (—Å–º–æ—Ç—Ä–∏–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∏ —Å–ª–µ–¥—É—é—â–∏–π)
                replacement = None
                
                # –°–º–æ—Ç—Ä–∏–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π
                if i > 0:
                    prev_speaker = segments[i-1].get('speaker', 'SPEAKER_UNKNOWN')
                    if prev_speaker != 'SPEAKER_UNKNOWN':
                        replacement = prev_speaker
                
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, —Å–º–æ—Ç—Ä–∏–º —Å–ª–µ–¥—É—é—â–∏–π
                if not replacement and i < len(segments) - 1:
                    next_speaker = segments[i+1].get('speaker', 'SPEAKER_UNKNOWN')
                    if next_speaker != 'SPEAKER_UNKNOWN':
                        replacement = next_speaker
                
                # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ –Ω–∞—à–ª–∏, –±–µ—Ä–µ–º –ø–µ—Ä–≤–æ–≥–æ –∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ
                if not replacement:
                    replacement = sorted(known_speakers)[0]
                
                seg_copy['speaker'] = replacement
                self._log(f"üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω SPEAKER_UNKNOWN ‚Üí {replacement}")
            
            fixed.append(seg_copy)
        
        return fixed
    
    def _fix_overlapping_timestamps(self, segments: List[Dict]) -> List[Dict]:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–µ—Å—è —Ç–∞–π–º–∏–Ω–≥–∏"""
        if not segments:
            return segments
        
        fixed = []
        for i, seg in enumerate(segments):
            seg_copy = seg.copy()
            start = float(seg_copy.get('start', 0))
            end = float(seg_copy.get('end', 0))
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Å–µ–≥–º–µ–Ω—Ç, –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ
            if i > 0:
                prev_end = float(fixed[i-1].get('end', 0))
                if start < prev_end:
                    # –ï—Å—Ç—å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ - —Å–¥–≤–∏–≥–∞–µ–º start –Ω–∞ prev_end
                    seg_copy['start'] = prev_end
                    self._log(f"üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ: {start} ‚Üí {prev_end}")
            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ end >= start
            if end < seg_copy['start']:
                seg_copy['end'] = seg_copy['start'] + 0.1  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            
            fixed.append(seg_copy)
        
        return fixed