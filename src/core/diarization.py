# -*- coding: utf-8 -*-
"""
–ú–æ–¥—É–ª—å –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ (—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∏–∫–µ—Ä–æ–≤) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º PyAnnote Audio.
–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π –¥–ª—è —Å–≤—è–∑–∫–∏ "–¢–µ–∫—Å—Ç -> –ö—Ç–æ —Å–∫–∞–∑–∞–ª".
"""
import os
import sys
from pathlib import Path
from typing import Optional, Callable, List, Dict, Tuple
import platform

# –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ Python –æ–∫—Ä—É–∂–µ–Ω–∏–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
def _log_import_info():
    """–õ–æ–≥–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ Python –æ–∫—Ä—É–∂–µ–Ω–∏–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏"""
    info = {
        'python_executable': sys.executable,
        'python_version': sys.version,
        'sys.path': sys.path[:5],  # –ü–µ—Ä–≤—ã–µ 5 –ø—É—Ç–µ–π
        'frozen': getattr(sys, 'frozen', False),
    }
    return info

try:
    from pyannote.audio import Pipeline
    from pyannote.core import Annotation, Segment
    PYANNOTE_AVAILABLE = True
    IMPORT_ERROR = None
except ImportError as e:
    PYANNOTE_AVAILABLE = False
    Pipeline = None
    Annotation = None
    Segment = None
    IMPORT_ERROR = str(e)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–∫—Ä—É–∂–µ–Ω–∏–∏ –ø—Ä–∏ –æ—à–∏–±–∫–µ
    IMPORT_ENV_INFO = _log_import_info()

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø—É—Ç–∏ –∏–∑ config
from core.config import APP_PATHS


def get_models_path():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –º–æ–¥–µ–ª—è–º–∏.
    –î–ª—è exe: —Ä—è–¥–æ–º —Å exe —Ñ–∞–π–ª–æ–º –≤ –ø–∞–ø–∫–µ models/
    –î–ª—è –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤: –≤ –ø–∞–ø–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è models/
    """
    if getattr(sys, 'frozen', False):
        # –ï—Å–ª–∏ –∑–∞–ø—É—â–µ–Ω–æ –∏–∑ exe —Ñ–∞–π–ª–∞
        if platform.system() == 'Windows':
            exe_dir = Path(sys.executable).parent
        else:
            exe_dir = Path(sys.executable).parent
        models_dir = exe_dir / "models"
    else:
        # –ï—Å–ª–∏ –∑–∞–ø—É—â–µ–Ω–æ –∏–∑ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤
        base_dir = Path(__file__).parent.parent.parent
        models_dir = base_dir / "models"
    
    models_dir.mkdir(parents=True, exist_ok=True)
    return models_dir


class Diarizer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ —Ñ–∞–π–ª–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º PyAnnote Audio.
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫—Ç–æ –∏ –∫–æ–≥–¥–∞ –≥–æ–≤–æ—Ä–∏–ª (—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∏–∫–µ—Ä–æ–≤).
    """
    
    def __init__(
        self,
        hf_token: Optional[str] = None,
        progress_callback: Optional[Callable[[str], None]] = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∏–∞—Ä–∏–∑–∞—Ç–æ—Ä–∞.
        
        Args:
            hf_token: Hugging Face token –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –º–æ–¥–µ–ª—è–º (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            progress_callback: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ
        """
        if not PYANNOTE_AVAILABLE:
            error_msg = "pyannote.audio –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install pyannote.audio"
            if 'IMPORT_ERROR' in globals():
                error_msg += f"\n–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {IMPORT_ERROR}"
            raise ImportError(error_msg)
        
        self.hf_token = hf_token
        self.progress_callback = progress_callback
        self.pipeline: Optional[Pipeline] = None
        self.models_path = get_models_path()
        
    def _log(self, message: str):
        """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        if self.progress_callback:
            self.progress_callback(message)
    
    def _load_pipeline(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç pipeline –¥–ª—è –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏"""
        if self.pipeline is not None:
            return
        
        self._log("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ PyAnnote...")
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏
            # –ú–æ–¥–µ–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∫–∞—á–∞–µ—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
            model_name = "pyannote/speaker-diarization-3.1"
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–∫–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
            if self.hf_token:
                self.pipeline = Pipeline.from_pretrained(
                    model_name,
                    use_auth_token=self.hf_token,
                    cache_dir=str(self.models_path)
                )
            else:
                # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–µ–∑ —Ç–æ–∫–µ–Ω–∞ (–¥–ª—è –ø—É–±–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π)
                try:
                    self.pipeline = Pipeline.from_pretrained(
                        model_name,
                        cache_dir=str(self.models_path)
                    )
                except Exception as e:
                    self._log(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –±–µ–∑ —Ç–æ–∫–µ–Ω–∞: {e}")
                    self._log("üí° –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ –Ω—É–∂–µ–Ω Hugging Face token")
                    self._log("   –ü–æ–ª—É—á–∏—Ç–µ —Ç–æ–∫–µ–Ω –Ω–∞ https://huggingface.co/settings/tokens")
                    raise
            
            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º pipeline –Ω–∞ GPU, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
            import torch
            if torch.cuda.is_available():
                self.pipeline.to(torch.device("cuda"))
                self._log("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ GPU")
            else:
                self._log("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ CPU")
                
        except Exception as e:
            self._log(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {str(e)}")
            raise
    
    def diarize(
        self,
        audio_path: str,
        num_speakers: Optional[int] = None,
        min_speakers: Optional[int] = None,
        max_speakers: Optional[int] = None
    ) -> Dict:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞.
        
        Args:
            audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ —Ñ–∞–π–ª—É
            num_speakers: –¢–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤ (–µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω–æ)
            min_speakers: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤
            max_speakers: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏:
            {
                "segments": —Å–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–ø–∏–∫–µ—Ä–µ,
                "speakers": —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ø–∏–∫–µ—Ä–æ–≤,
                "total_duration": –æ–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            }
        """
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_path}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º pipeline, –µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω
        self._load_pipeline()
        
        self._log(f"üéôÔ∏è –ù–∞—á–∞–ª–æ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏: {os.path.basename(audio_path)}")
        
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é
            diarization = self.pipeline(
                audio_path,
                num_speakers=num_speakers,
                min_speakers=min_speakers,
                max_speakers=max_speakers
            )
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —É–¥–æ–±–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            segments = []
            speakers = set()
            
            for turn, _, speaker in diarization.itertracks(yield_label=True):
                segments.append({
                    "start": turn.start,
                    "end": turn.end,
                    "speaker": speaker,
                    "duration": turn.end - turn.start
                })
                speakers.add(speaker)
            
            speakers_list = sorted(list(speakers))
            
            self._log(f"‚úÖ –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
            self._log(f"üë• –ù–∞–π–¥–µ–Ω–æ —Å–ø–∏–∫–µ—Ä–æ–≤: {len(speakers_list)}")
            self._log(f"üìä –í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(segments)}")
            
            return {
                "segments": segments,
                "speakers": speakers_list,
                "total_duration": diarization.get_timeline().extent().end if segments else 0.0
            }
            
        except Exception as e:
            self._log(f"‚ùå –û—à–∏–±–∫–∞ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏: {str(e)}")
            raise


def merge_transcription_with_diarization(
    transcription_segments: List[Dict],
    diarization_segments: List[Dict]
) -> List[Dict]:
    """
    –°–≤—è–∑—ã–≤–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏.
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫–æ–π —Å–ø–∏–∫–µ—Ä —Å–∫–∞–∑–∞–ª –∫–∞–∂–¥—ã–π —Å–µ–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞.
    
    Args:
        transcription_segments: –°–µ–≥–º–µ–Ω—Ç—ã –∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (—Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏)
        diarization_segments: –°–µ–≥–º–µ–Ω—Ç—ã –∏–∑ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ (—Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–ø–∏–∫–µ—Ä–µ)
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π (—Ç–µ–∫—Å—Ç + —Å–ø–∏–∫–µ—Ä)
    """
    merged_segments = []
    
    for trans_seg in transcription_segments:
        trans_start = trans_seg.get("start", 0)
        trans_end = trans_seg.get("end", trans_start)
        trans_mid = (trans_start + trans_end) / 2
        
        # –ù–∞—Ö–æ–¥–∏–º —Å–ø–∏–∫–µ—Ä–∞ –¥–ª—è —ç—Ç–æ–≥–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
        speaker = None
        max_overlap = 0
        
        for diar_seg in diarization_segments:
            diar_start = diar_seg.get("start", 0)
            diar_end = diar_seg.get("end", diar_start)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤
            overlap_start = max(trans_start, diar_start)
            overlap_end = min(trans_end, diar_end)
            overlap = max(0, overlap_end - overlap_start)
            
            if overlap > max_overlap:
                max_overlap = overlap
                speaker = diar_seg.get("speaker")
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç
        merged_seg = trans_seg.copy()
        merged_seg["speaker"] = speaker if speaker else "UNKNOWN"
        merged_segments.append(merged_seg)
    
    return merged_segments

