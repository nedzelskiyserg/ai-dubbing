# -*- coding: utf-8 -*-
"""
Voice Cloning Module using Coqui XTTS v2
–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥—É–±–ª—è–∂–∞ —Å –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≥–æ–ª–æ—Å–∞ —Å–ø–∏–∫–µ—Ä–æ–≤
"""
import os
import logging
import subprocess
import json
import sys
import time
from pathlib import Path
from typing import List, Dict, Optional, Callable
import torch
from pydub import AudioSegment

# –ü—ã—Ç–∞–µ–º—Å—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å TTS (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –∏ —Å—Ç–∞—Ä—ã–π TTS, –∏ –Ω–æ–≤—ã–π coqui-tts)
TTS_AVAILABLE = False
TTS = None
TTS_ERROR = None

try:
    # –ü—Ä–æ–±—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å TTS API
    from TTS.api import TTS
    TTS_AVAILABLE = True
except ImportError as e:
    # TTS –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
    TTS_AVAILABLE = False
    TTS = None
    TTS_ERROR = f"ImportError: {str(e)}"
except (TypeError, SyntaxError) as e:
    # –û—à–∏–±–∫–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ Python –≤–µ—Ä—Å–∏–∏ (–æ–±—ã—á–Ω–æ Python < 3.10)
    TTS_AVAILABLE = False
    TTS = None
    TTS_ERROR = f"CompatibilityError: {str(e)}"
except Exception as e:
    # –î—Ä—É–≥–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏
    TTS_AVAILABLE = False
    TTS = None
    TTS_ERROR = f"UnexpectedError: {str(e)}"


class VoiceCloner:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥—É–±–ª—è–∂–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Coqui XTTS v2.
    """
    
    def __init__(
        self,
        model_name: str = "tts_models/multilingual/multi-dataset/xtts_v2",
        progress_callback: Optional[Callable[[str], None]] = None,
        should_stop_callback: Optional[Callable[[], bool]] = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è VoiceCloner.
        
        Args:
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ XTTS (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é xtts_v2)
            progress_callback: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        """
        # –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–æ–º–ø—Ç –ª–∏—Ü–µ–Ω–∑–∏–∏
        os.environ["COQUI_TOS_AGREED"] = "1"
        
        self.model_name = model_name
        self.progress_callback = progress_callback
        self.should_stop_callback = should_stop_callback
        self.model = None
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        self.device = self._detect_device()
        
        # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.voices_dir = Path("voices")
        self.voices_dir.mkdir(exist_ok=True)
        
        self.temp_tts_dir = Path("temp/tts_parts")
        self.temp_tts_dir.mkdir(parents=True, exist_ok=True)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ venv_tts –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ subprocess
        self.venv_tts_path = self._find_venv_tts()
        self.use_venv_tts = self.venv_tts_path is not None and not TTS_AVAILABLE
        
        if self.use_venv_tts:
            self._log(f"üé§ VoiceCloner –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è venv_tts)")
        else:
            self._log(f"üé§ VoiceCloner –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device})")
    
    def _log(self, msg: str):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ UI –∏ –∫–æ–Ω—Å–æ–ª—å"""
        print(msg)
        if self.progress_callback:
            self.progress_callback(msg)
    
    def _detect_device(self) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è TTS.
        –î–ª—è Mac (Apple Silicon) –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏.
        """
        if torch.cuda.is_available():
            return "cuda"
        
        # –î–ª—è Mac –ø—Ä–æ–≤–µ—Ä—è–µ–º MPS, –Ω–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            # MPS –¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–æ XTTS –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å—Ç–∞–±–∏–ª–µ–Ω –Ω–∞ MPS
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –Ω–∞ Mac
            return "cpu"
        
        return "cpu"
    
    def _find_venv_tts(self) -> Optional[Path]:
        """
        –ò—â–µ—Ç venv_tts –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏–ª–∏ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏—Ö.
        """
        current = Path.cwd()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        venv_path = current / "venv_tts" / "bin" / "python3"
        if venv_path.exists():
            return venv_path
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (–¥–æ 3 —É—Ä–æ–≤–Ω–µ–π –≤–≤–µ—Ä—Ö)
        for i in range(3):
            parent = current.parent if i > 0 else current
            venv_path = parent / "venv_tts" / "bin" / "python3"
            if venv_path.exists():
                return venv_path
        
        return None
    
    def _load_model(self):
        """–õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ XTTS"""
        if self.model is not None:
            return
        
        # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º venv_tts —á–µ—Ä–µ–∑ subprocess, –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ–º
        if self.use_venv_tts:
            self._log(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è venv_tts –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ TTS (Python 3.11+)")
            return
        
        if not TTS_AVAILABLE:
            import sys
            python_version = f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
            
            error_msg = (
                f"‚ùå TTS (Coqui TTS) –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.\n"
                f"   –¢–µ–∫—É—â–∞—è –≤–µ—Ä—Å–∏—è Python: {python_version}\n"
                f"   –¢—Ä–µ–±—É–µ—Ç—Å—è: Python 3.10+\n\n"
            )
            
            if TTS_ERROR:
                error_msg += f"   –û—à–∏–±–∫–∞: {TTS_ERROR}\n\n"
            
            error_msg += (
                "üí° –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞:\n"
                "   –ó–∞–ø—É—Å—Ç–∏—Ç–µ: ./setup_voice_cloning.sh\n\n"
                "   –ò–ª–∏ –≤—Ä—É—á–Ω—É—é:\n"
                "   1. brew install python@3.11\n"
                "   2. python3.11 -m venv venv_tts\n"
                "   3. source venv_tts/bin/activate\n"
                "   4. pip install coqui-tts pydub\n"
            )
            
            raise ImportError(error_msg)
        
        self._log(f"üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ XTTS: {self.model_name}...")
        try:
            self.model = TTS(model_name=self.model_name, progress_bar=False)
            self.model.to(self.device)
            self._log(f"‚úÖ –ú–æ–¥–µ–ª—å XTTS –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {self.device}")
        except Exception as e:
            self._log(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ XTTS: {e}")
            raise
    
    def _generate_tts_via_venv(self, text: str, speaker_wav: str, output_path: str, language: str, segment_index: int = None, total_segments: int = None) -> bool:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç TTS —á–µ—Ä–µ–∑ venv_tts –∏—Å–ø–æ–ª—å–∑—É—è subprocess.
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            speaker_wav: –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–µ –∞—É–¥–∏–æ
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            language: –Ø–∑—ã–∫
            segment_index: –ò–Ω–¥–µ–∫—Å —Å–µ–≥–º–µ–Ω—Ç–∞ (–¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
            total_segments: –í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (–¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
        
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
        """
        if not self.venv_tts_path:
            return False
        
        # –ü—É—Ç—å –∫ —Å–∫—Ä–∏–ø—Ç—É-–≤–æ—Ä–∫–µ—Ä—É (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏)
        worker_script = Path(__file__).parent.absolute() / "tts_worker.py"
        
        if not worker_script.exists():
            self._log(f"‚ùå –°–∫—Ä–∏–ø—Ç tts_worker.py –Ω–µ –Ω–∞–π–¥–µ–Ω: {worker_script}")
            return False
        
        start_time = time.time()
        
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏
            input_data = {
                "text": text,
                "speaker_wav": speaker_wav,
                "output_path": output_path,
                "language": language,
                "model_name": self.model_name
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–µ–≥–º–µ–Ω—Ç–µ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ worker
            if segment_index is not None and total_segments is not None:
                input_data["segment_info"] = {
                    "index": segment_index + 1,
                    "total": total_segments
                }
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–ø—Ç —á–µ—Ä–µ–∑ venv_tts Python
            result = subprocess.run(
                [str(self.venv_tts_path), str(worker_script)],
                input=json.dumps(input_data),
                capture_output=True,
                text=True,
                timeout=300  # 5 –º–∏–Ω—É—Ç –º–∞–∫—Å–∏–º—É–º –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç
            )
            
            # –õ–æ–≥–∏—Ä—É–µ–º stderr (—Ç–∞–º –≤—ã–≤–æ–¥—è—Ç—Å—è —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ worker)
            if result.stderr:
                for line in result.stderr.strip().split('\n'):
                    if line.strip():
                        self._log(line)
            
            if result.returncode != 0:
                self._log(f"‚ùå –û—à–∏–±–∫–∞ subprocess (–∫–æ–¥ {result.returncode}): {result.stderr}")
                return False
            
            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            output = json.loads(result.stdout)
            
            if not output.get("success"):
                self._log(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ TTS: {output.get('error', 'Unknown error')}")
                return False
            
            # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            total_time = time.time() - start_time
            load_time = output.get("load_time", 0)
            gen_time = output.get("gen_time", 0)
            
            if segment_index is not None and total_segments is not None:
                progress = ((segment_index + 1) / total_segments) * 100
                if load_time > 0:
                    self._log(f"   ‚è±Ô∏è –í—Ä–µ–º—è: –∑–∞–≥—Ä—É–∑–∫–∞ {load_time:.1f}—Å + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è {gen_time:.1f}—Å = {total_time:.1f}—Å | –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress:.1f}%")
                else:
                    self._log(f"   ‚è±Ô∏è –í—Ä–µ–º—è: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è {gen_time:.1f}—Å (–º–æ–¥–µ–ª—å —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞) | –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress:.1f}%")
            
            return True
            
        except subprocess.TimeoutExpired:
            self._log(f"‚ùå –¢–∞–π–º–∞—É—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ TTS (–ø—Ä–µ–≤—ã—à–µ–Ω–æ 5 –º–∏–Ω—É—Ç)")
            return False
        except json.JSONDecodeError as e:
            self._log(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {e}")
            return False
        except Exception as e:
            self._log(f"‚ùå –û—à–∏–±–∫–∞ subprocess: {e}")
            return False
    
    def extract_speaker_samples(
        self,
        audio_path: str,
        segments: List[Dict]
    ) -> Dict[str, str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –∞—É–¥–∏–æ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞.
        
        –ò—â–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é 3-10 —Å–µ–∫—É–Ω–¥ (–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å–ø–∏–∫–µ—Ä–∞).
        –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: —á–µ–º –±–æ–ª—å—à–µ –≤ —ç—Ç–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ - —Ç–µ–º –ª—É—á—à–µ.
        –ï—Å–ª–∏ —Ç–∞–∫–∏—Ö –Ω–µ—Ç, –±–µ—Ä–µ—Ç —Å–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç.
        
        Args:
            audio_path: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–ø–∏–∫–µ—Ä–∞—Ö –∏ —Ç–∞–π–º–∏–Ω–≥–∞—Ö
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å {speaker_id: path_to_sample.wav}
        """
        self._log(f"üéØ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã—Ö –∞—É–¥–∏–æ –¥–ª—è —Å–ø–∏–∫–µ—Ä–æ–≤...")
        
        if not segments:
            self._log("‚ö†Ô∏è –ù–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return {}
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∞—É–¥–∏–æ
        try:
            audio = AudioSegment.from_file(audio_path)
            self._log(f"‚úÖ –ò—Å—Ö–æ–¥–Ω–æ–µ –∞—É–¥–∏–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(audio) / 1000:.1f} —Å–µ–∫")
        except Exception as e:
            self._log(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ: {e}")
            return {}
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º
        speaker_segments = {}
        for seg in segments:
            speaker = seg.get("speaker", "SPEAKER_UNKNOWN")
            if speaker not in speaker_segments:
                speaker_segments[speaker] = []
            speaker_segments[speaker].append(seg)
        
        self._log(f"üìä –ù–∞–π–¥–µ–Ω–æ —Å–ø–∏–∫–µ—Ä–æ–≤: {len(speaker_segments)}")
        
        speaker_samples = {}
        
        for speaker, segs in speaker_segments.items():
            # –ò—â–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç (3-10 —Å–µ–∫—É–Ω–¥, —á–µ–º –±–æ–ª—å—à–µ - —Ç–µ–º –ª—É—á—à–µ)
            best_seg = None
            best_duration = 0
            
            for seg in segs:
                start = float(seg.get("start", 0))
                end = float(seg.get("end", 0))
                duration = end - start
                
                # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å–ø–∏–∫–µ—Ä–∞: 3-10 —Å–µ–∫—É–Ω–¥
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: —á–µ–º –±–æ–ª—å—à–µ –≤ —ç—Ç–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ - —Ç–µ–º –ª—É—á—à–µ
                if 3.0 <= duration <= 10.0:
                    # –ï—Å–ª–∏ —ç—Ç–æ –ª—É—á—à–∏–π —Å–µ–≥–º–µ–Ω—Ç –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ (–¥–ª–∏–Ω–Ω–µ–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ)
                    if duration > best_duration:
                        best_seg = seg
                        best_duration = duration
                        # –ù–µ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∏—Å–∫–∞—Ç—å –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–π –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
                
                # –ï—Å–ª–∏ –Ω–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ, –∑–∞–ø–æ–º–∏–Ω–∞–µ–º —Å–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π
                elif best_duration == 0 and duration > best_duration:
                    best_duration = duration
                    best_seg = seg
            
            if best_seg is None:
                self._log(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è {speaker}")
                continue
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ —Å–µ–≥–º–µ–Ω—Ç
            start_ms = int(best_seg.get("start", 0) * 1000)
            end_ms = int(best_seg.get("end", 0) * 1000)
            
            try:
                sample_audio = audio[start_ms:end_ms]
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–π —Ñ–∞–π–ª
                sample_path = self.voices_dir / f"{speaker}_sample.wav"
                sample_audio.export(str(sample_path), format="wav")
                
                speaker_samples[speaker] = str(sample_path)
                
                self._log(
                    f"‚úÖ –†–µ—Ñ–µ—Ä–µ–Ω—Å –¥–ª—è {speaker}: {best_duration:.1f}—Å "
                    f"({sample_path.name})"
                )
            except Exception as e:
                self._log(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞—É–¥–∏–æ –¥–ª—è {speaker}: {e}")
                continue
        
        self._log(f"üéØ –ò–∑–≤–ª–µ—á–µ–Ω–æ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–≤: {len(speaker_samples)}/{len(speaker_segments)}")
        return speaker_samples
    
    def generate_dubbing(
        self,
        segments: List[Dict],
        speaker_samples: Dict[str, str],
        target_lang: str = "ru"
    ) -> List[Dict]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥—É–±–ª—è–∂ –¥–ª—è –≤—Å–µ—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≥–æ–ª–æ—Å–∞.
        
        Args:
            segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
            speaker_samples: –°–ª–æ–≤–∞—Ä—å {speaker_id: path_to_sample.wav}
            target_lang: –¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "ru")
            
        Returns:
            –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º –∫–ª—é—á–æ–º "audio_file"
        """
        if not segments:
            self._log("‚ö†Ô∏è –ù–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥—É–±–ª—è–∂–∞")
            return segments
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å (–ª–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞)
        self._load_model()
        
        if not speaker_samples:
            self._log("‚ö†Ô∏è –ù–µ—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã—Ö –∞—É–¥–∏–æ –¥–ª—è —Å–ø–∏–∫–µ—Ä–æ–≤")
            return segments
        
        total_segments = len(segments)
        self._log(f"üé¨ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥—É–±–ª—è–∂–∞ –¥–ª—è {total_segments} —Å–µ–≥–º–µ–Ω—Ç–æ–≤...")
        
        # Fallback: –µ—Å–ª–∏ –¥–ª—è —Å–ø–∏–∫–µ—Ä–∞ –Ω–µ—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π
        fallback_sample = list(speaker_samples.values())[0] if speaker_samples else None
        
        updated_segments = []
        success_count = 0
        error_count = 0
        start_time = time.time()
        
        for i, seg in enumerate(segments):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤ —Ü–∏–∫–ª–µ
            if self.should_stop_callback and self.should_stop_callback():
                self._log("‚èπÔ∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥—É–±–ª—è–∂–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                raise InterruptedError("Processing stopped by user")
            
            speaker = seg.get("speaker", "SPEAKER_UNKNOWN")
            text = seg.get("text", "").strip()
            
            if not text:
                self._log(f"‚ö†Ô∏è [{i+1}/{total_segments}] –°–µ–≥–º–µ–Ω—Ç {i}: –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                updated_segments.append(seg)
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Å–ø–∏–∫–µ—Ä–∞
            speaker_wav = speaker_samples.get(speaker, fallback_sample)
            
            if not speaker_wav or not os.path.exists(speaker_wav):
                self._log(f"‚ö†Ô∏è [{i+1}/{total_segments}] –°–µ–≥–º–µ–Ω—Ç {i}: –Ω–µ—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞ –¥–ª—è {speaker}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                updated_segments.append(seg)
                error_count += 1
                continue
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞—É–¥–∏–æ
            output_path = self.temp_tts_dir / f"segment_{i:04d}.wav"
            
            try:
                # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                progress = ((i + 1) / total_segments) * 100
                elapsed = time.time() - start_time
                avg_time_per_segment = elapsed / (i + 1) if i > 0 else 0
                remaining_segments = total_segments - (i + 1)
                estimated_remaining = avg_time_per_segment * remaining_segments
                
                self._log(f"üé§ [{i+1}/{total_segments}] ({progress:.1f}%) {speaker} | {len(text)} —Å–∏–º–≤–æ–ª–æ–≤ | ‚è±Ô∏è ~{estimated_remaining/60:.1f} –º–∏–Ω –æ—Å—Ç–∞–ª–æ—Å—å")
                
                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è TTS
                if self.use_venv_tts:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º venv_tts —á–µ—Ä–µ–∑ subprocess
                    success = self._generate_tts_via_venv(
                        text=text,
                        speaker_wav=speaker_wav,
                        output_path=str(output_path),
                        language=target_lang,
                        segment_index=i,
                        total_segments=total_segments
                    )
                    if not success:
                        raise Exception("–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ venv_tts")
                else:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–π –≤—ã–∑–æ–≤ TTS API
                    seg_start = time.time()
                    self.model.tts_to_file(
                        text=text,
                        speaker_wav=speaker_wav,
                        language=target_lang,
                        file_path=str(output_path),
                        split_sentences=False  # –í–∞–∂–Ω–æ! –ú—ã —Å–∞–º–∏ —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                    )
                    seg_time = time.time() - seg_start
                    self._log(f"   ‚è±Ô∏è –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {seg_time:.1f}—Å")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ–≥–º–µ–Ω—Ç
                seg_copy = seg.copy()
                seg_copy["audio_file"] = str(output_path)
                updated_segments.append(seg_copy)
                
                success_count += 1
                
            except InterruptedError:
                self._log("‚èπÔ∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥—É–±–ª—è–∂–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                raise
            except Exception as e:
                self._log(f"‚ùå [{i+1}/{total_segments}] –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞ {i} ({speaker}): {e}")
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ–≥–º–µ–Ω—Ç –±–µ–∑ –∞—É–¥–∏–æ, —á—Ç–æ–±—ã –Ω–µ –ø–æ—Ç–µ—Ä—è—Ç—å –¥–∞–Ω–Ω—ã–µ
                updated_segments.append(seg)
                error_count += 1
                continue
        
        total_time = time.time() - start_time
        self._log(
            f"‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: —É—Å–ø–µ—à–Ω–æ {success_count}/{total_segments}, "
            f"–æ—à–∏–±–æ–∫ {error_count} | –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time/60:.1f} –º–∏–Ω ({total_time:.1f}—Å)"
        )
        
        return updated_segments
    
    def merge_audio_segments(
        self,
        segments: List[Dict],
        output_path: str
    ) -> str:
        """
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –∞—É–¥–∏–æ —Å–µ–≥–º–µ–Ω—Ç—ã –≤ –æ–¥–∏–Ω —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª.
        
        Args:
            segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –∫–ª—é—á–æ–º "audio_file"
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ
            original_audio_path: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ - –ø—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∞—É–¥–∏–æ (–¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏)
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        self._log(f"üé¨ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ {len(segments)} –∞—É–¥–∏–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤...")
        
        if not segments:
            raise ValueError("–ù–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
        audio_segments = []
        missing_files = []
        
        for i, seg in enumerate(segments):
            audio_file = seg.get("audio_file")
            if not audio_file or not os.path.exists(audio_file):
                missing_files.append(i)
                # –°–æ–∑–¥–∞–µ–º —Ç–∏—à–∏–Ω—É –¥–ª—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                start = float(seg.get("start", 0))
                end = float(seg.get("end", start + 1.0))
                duration_ms = int((end - start) * 1000)
                silence = AudioSegment.silent(duration=duration_ms)
                audio_segments.append(silence)
                self._log(f"‚ö†Ô∏è –°–µ–≥–º–µ–Ω—Ç {i}: —Ñ–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –¥–æ–±–∞–≤–ª–µ–Ω–∞ —Ç–∏—à–∏–Ω–∞ ({duration_ms}ms)")
            else:
                try:
                    audio = AudioSegment.from_file(audio_file)
                    audio_segments.append(audio)
                except Exception as e:
                    self._log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞ {i}: {e}")
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∏—à–∏–Ω—É –≤–º–µ—Å—Ç–æ –æ—à–∏–±–∫–∏
                    start = float(seg.get("start", 0))
                    end = float(seg.get("end", start + 1.0))
                    duration_ms = int((end - start) * 1000)
                    silence = AudioSegment.silent(duration=duration_ms)
                    audio_segments.append(silence)
        
        if missing_files:
            self._log(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(missing_files)}")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã
        if not audio_segments:
            raise ValueError("–ù–µ—Ç –∞—É–¥–∏–æ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
        
        self._log(f"üîó –°–∫–ª–µ–π–∫–∞ {len(audio_segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤...")
        final_audio = sum(audio_segments)
        
        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
        output_path_obj = Path(output_path)
        output_path_obj.parent.mkdir(parents=True, exist_ok=True)
        
        final_audio.export(str(output_path), format="wav")
        
        duration_sec = len(final_audio) / 1000.0
        self._log(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω–æ–µ –∞—É–¥–∏–æ —Å–æ–∑–¥–∞–Ω–æ: {output_path}")
        self._log(f"   –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration_sec:.1f} —Å–µ–∫—É–Ω–¥")
        
        return str(output_path)
    
    def merge_audio_segments(
        self,
        segments: List[Dict],
        output_path: str
    ) -> str:
        """
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –∞—É–¥–∏–æ —Å–µ–≥–º–µ–Ω—Ç—ã –≤ –æ–¥–∏–Ω —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª.
        
        Args:
            segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –∫–ª—é—á–æ–º "audio_file"
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        self._log(f"üé¨ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ {len(segments)} –∞—É–¥–∏–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤...")
        
        if not segments:
            raise ValueError("–ù–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
        audio_segments = []
        missing_files = []
        
        for i, seg in enumerate(segments):
            audio_file = seg.get("audio_file")
            if not audio_file or not os.path.exists(audio_file):
                missing_files.append(i)
                # –°–æ–∑–¥–∞–µ–º —Ç–∏—à–∏–Ω—É –¥–ª—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                start = float(seg.get("start", 0))
                end = float(seg.get("end", start + 1.0))
                duration_ms = int((end - start) * 1000)
                silence = AudioSegment.silent(duration=duration_ms)
                audio_segments.append(silence)
                self._log(f"‚ö†Ô∏è –°–µ–≥–º–µ–Ω—Ç {i}: —Ñ–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –¥–æ–±–∞–≤–ª–µ–Ω–∞ —Ç–∏—à–∏–Ω–∞ ({duration_ms}ms)")
            else:
                try:
                    audio = AudioSegment.from_file(audio_file)
                    audio_segments.append(audio)
                except Exception as e:
                    self._log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞ {i}: {e}")
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∏—à–∏–Ω—É –≤–º–µ—Å—Ç–æ –æ—à–∏–±–∫–∏
                    start = float(seg.get("start", 0))
                    end = float(seg.get("end", start + 1.0))
                    duration_ms = int((end - start) * 1000)
                    silence = AudioSegment.silent(duration=duration_ms)
                    audio_segments.append(silence)
        
        if missing_files:
            self._log(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(missing_files)}")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã
        if not audio_segments:
            raise ValueError("–ù–µ—Ç –∞—É–¥–∏–æ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
        
        self._log(f"üîó –°–∫–ª–µ–π–∫–∞ {len(audio_segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤...")
        final_audio = sum(audio_segments)
        
        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
        output_path_obj = Path(output_path)
        output_path_obj.parent.mkdir(parents=True, exist_ok=True)
        
        final_audio.export(str(output_path), format="wav")
        
        duration_sec = len(final_audio) / 1000.0
        self._log(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω–æ–µ –∞—É–¥–∏–æ —Å–æ–∑–¥–∞–Ω–æ: {output_path}")
        self._log(f"   –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration_sec:.1f} —Å–µ–∫—É–Ω–¥")
        
        return str(output_path)
    
    def cleanup_temp_files(self):
        """–û—á–∏—â–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã TTS"""
        try:
            if self.temp_tts_dir.exists():
                for file in self.temp_tts_dir.glob("*.wav"):
                    file.unlink()
                self._log(f"üßπ –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã TTS –æ—á–∏—â–µ–Ω—ã")
        except Exception as e:
            self._log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {e}")
