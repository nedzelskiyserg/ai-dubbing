# -*- coding: utf-8 -*-
import os
import sys
from pathlib import Path
from typing import Optional, Callable
from faster_whisper import WhisperModel
import platform

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø—É—Ç–∏ –∏–∑ config
from core.config import APP_PATHS

def get_models_path():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –º–æ–¥–µ–ª—è–º–∏.
    –î–ª—è exe: —Ä—è–¥–æ–º —Å exe —Ñ–∞–π–ª–æ–º –≤ –ø–∞–ø–∫–µ models/
    –î–ª—è –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤: –≤ –ø–∞–ø–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è models/
    """
    if getattr(sys, 'frozen', False):
        # –ï—Å–ª–∏ –∑–∞–ø—É—â–µ–Ω–æ –∏–∑ exe —Ñ–∞–π–ª–∞
        if platform.system() == 'Windows':
            # –ù–∞ Windows exe –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ sys.executable
            exe_dir = Path(sys.executable).parent
        else:
            # –ù–∞ macOS/Linux
            exe_dir = Path(sys.executable).parent
        models_dir = exe_dir / "models"
    else:
        # –ï—Å–ª–∏ –∑–∞–ø—É—â–µ–Ω–æ –∏–∑ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤
        base_dir = Path(__file__).parent.parent.parent
        models_dir = base_dir / "models"
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    models_dir.mkdir(parents=True, exist_ok=True)
    return models_dir

class Transcriber:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ —Ñ–∞–π–ª–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º faster-whisper.
    –†–∞–±–æ—Ç–∞–µ—Ç –≤ –Ω–µ–±–ª–æ–∫–∏—Ä—É—é—â–µ–º —Ä–µ–∂–∏–º–µ –¥–ª—è NiceGUI.
    """
    
    def __init__(self, model_size: str = "base", device: str = "auto", progress_callback: Optional[Callable[[str], None]] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–µ—Ä–∞.
        
        Args:
            model_size: –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ ("tiny", "base", "small", "medium", "large-v2", "large-v3")
            device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ ("cpu", "cuda", "auto")
            progress_callback: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ (–ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Å—Ç—Ä–æ–∫—É —Å–æ–æ–±—â–µ–Ω–∏—è)
        """
        self.model_size = model_size
        self.device = device
        self.progress_callback = progress_callback
        self.model: Optional[WhisperModel] = None
        self.models_path = get_models_path()
        
    def _log(self, message: str):
        """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        if self.progress_callback:
            self.progress_callback(message)
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å Whisper. –°–∫–∞—á–∏–≤–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."""
        if self.model is not None:
            return
        
        self._log(f"üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper ({self.model_size})...")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
        # faster-whisper –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∫–∞—á–∞–µ—Ç –º–æ–¥–µ–ª—å –≤ –∫—ç—à, –µ—Å–ª–∏ —É–∫–∞–∑–∞—Ç—å download_root
        download_root = str(self.models_path)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º compute_type –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        # –î–ª—è CPU –∏—Å–ø–æ–ª—å–∑—É–µ–º int8, –¥–ª—è GPU –ø—Ä–æ–±—É–µ–º float16, –µ—Å–ª–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è - int8_float16
        compute_type = "int8"  # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è CPU
        
        if self.device == "auto":
            # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            try:
                import torch
                if torch.cuda.is_available():
                    self.device = "cuda"
                    compute_type = "float16"  # –î–ª—è CUDA –ø—Ä–æ–±—É–µ–º float16
                else:
                    self.device = "cpu"
                    compute_type = "int8"
            except ImportError:
                # –ï—Å–ª–∏ torch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU
                self.device = "cpu"
                compute_type = "int8"
        elif self.device == "cuda":
            compute_type = "float16"
        else:
            compute_type = "int8"
        
        try:
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º compute_type
            self.model = WhisperModel(
                self.model_size,
                device=self.device,
                download_root=download_root,
                compute_type=compute_type
            )
            self._log(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {self.model_size} (—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}, —Ç–∏–ø: {compute_type})")
        except Exception as e:
            # –ï—Å–ª–∏ float16 –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è, –ø—Ä–æ–±—É–µ–º int8_float16 –∏–ª–∏ int8
            if "float16" in str(e).lower():
                self._log(f"‚ö†Ô∏è Float16 –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è, –ø—Ä–æ–±—É–µ–º int8...")
                try:
                    compute_type = "int8_float16" if self.device != "cpu" else "int8"
                    self.model = WhisperModel(
                        self.model_size,
                        device=self.device,
                        download_root=download_root,
                        compute_type=compute_type
                    )
                    self._log(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {self.model_size} (—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}, —Ç–∏–ø: {compute_type})")
                except Exception as e2:
                    # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - —Ç–æ–ª—å–∫–æ int8
                    if compute_type != "int8":
                        self._log(f"‚ö†Ô∏è –ü—Ä–æ–±—É–µ–º int8...")
                        self.model = WhisperModel(
                            self.model_size,
                            device="cpu",  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ CPU —Å int8
                            download_root=download_root,
                            compute_type="int8"
                        )
                        self._log(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {self.model_size} (—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cpu, —Ç–∏–ø: int8)")
                    else:
                        self._log(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {str(e2)}")
                        raise
            else:
                self._log(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {str(e)}")
                raise
    
    def transcribe(
        self,
        audio_path: str,
        language: Optional[str] = None,
        task: str = "transcribe",
        beam_size: int = 5,
        best_of: int = 5,
        patience: float = 1.0,
        length_penalty: float = 1.0,
        temperature: float = 0.0,
        compression_ratio_threshold: float = 2.4,
        log_prob_threshold: float = -1.0,
        no_speech_threshold: float = 0.6,
        condition_on_previous_text: bool = True,
        initial_prompt: Optional[str] = None,
        word_timestamps: bool = True,
        prepend_punctuations: str = """\"'¬ø([{-""",
        append_punctuations: str = """\"'.„ÄÇ,Ôºå!ÔºÅ?Ôºü:Ôºö")]}„ÄÅ""",
        vad_filter: bool = True,
        vad_parameters: Optional[dict] = None
    ) -> dict:
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ —Ñ–∞–π–ª.
        
        Args:
            audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ —Ñ–∞–π–ª—É
            language: –Ø–∑—ã–∫ (–∫–æ–¥ ISO 639-1, –Ω–∞–ø—Ä–∏–º–µ—Ä "ru", "en"). –ï—Å–ª–∏ None, –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            task: "transcribe" –∏–ª–∏ "translate"
            word_timestamps: –í–∫–ª—é—á–∞—Ç—å –ª–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞
            vad_filter: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –≥–æ–ª–æ—Å–æ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
            ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:
            {
                "text": –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏,
                "segments": —Å–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏,
                "language": –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π —è–∑—ã–∫,
                "language_probability": –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —è–∑—ã–∫–∞
            }
        """
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_path}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
        self._load_model()
        
        self._log(f"üé§ –ù–∞—á–∞–ª–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {os.path.basename(audio_path)}")
        
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
            segments, info = self.model.transcribe(
                audio_path,
                language=language,
                task=task,
                beam_size=beam_size,
                best_of=best_of,
                patience=patience,
                length_penalty=length_penalty,
                temperature=temperature,
                compression_ratio_threshold=compression_ratio_threshold,
                log_prob_threshold=log_prob_threshold,
                no_speech_threshold=no_speech_threshold,
                condition_on_previous_text=condition_on_previous_text,
                initial_prompt=initial_prompt,
                word_timestamps=word_timestamps,
                prepend_punctuations=prepend_punctuations,
                append_punctuations=append_punctuations,
                vad_filter=vad_filter,
                vad_parameters=vad_parameters
            )
            
            self._log(f"üåç –û–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π —è–∑—ã–∫: {info.language} (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {info.language_probability:.2%})")
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            full_text = ""
            segments_list = []
            
            segment_count = 0
            for segment in segments:
                segment_count += 1
                segment_text = segment.text.strip()
                full_text += segment_text + " "
                
                segment_data = {
                    "id": segment.id,
                    "start": segment.start,
                    "end": segment.end,
                    "text": segment_text,
                    "words": []
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
                if word_timestamps and hasattr(segment, 'words') and segment.words:
                    for word in segment.words:
                        segment_data["words"].append({
                            "word": word.word,
                            "start": word.start,
                            "end": word.end,
                            "probability": word.probability
                        })
                
                segments_list.append(segment_data)
                
                # –û—Ç—á–µ—Ç –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ –∫–∞–∂–¥—ã–µ 10 —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                if segment_count % 10 == 0:
                    self._log(f"üìù –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {segment_count}...")
            
            self._log(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {segment_count}")
            
            return {
                "text": full_text.strip(),
                "segments": segments_list,
                "language": info.language,
                "language_probability": info.language_probability
            }
            
        except Exception as e:
            self._log(f"‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {str(e)}")
            raise

