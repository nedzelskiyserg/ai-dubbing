# -*- coding: utf-8 -*-
import os
import sys
import gc
import re
import platform
import warnings
import traceback
from typing import Optional, Callable, List, Dict
import torch

# –ü–æ–¥–∞–≤–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
warnings.filterwarnings('ignore')

# --- –ü–ê–¢–ß –î–õ–Ø PyTorch 2.6+ (CRITICAL) ---
# WhisperX –∏ pyannote –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Å—Ç–∞—Ä—ã–π —Å–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤.
# –ë–µ–∑ —ç—Ç–æ–≥–æ –ø–∞—Ç—á–∞ –Ω–æ–≤—ã–µ –≤–µ—Ä—Å–∏–∏ torch –≤—ã–¥–∞—é—Ç –æ—à–∏–±–∫—É –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.
try:
    import functools
    original_load = torch.load
    
    @functools.wraps(original_load)
    def patched_load(*args, **kwargs):
        if 'weights_only' in kwargs:
            kwargs['weights_only'] = False
        return original_load(*args, **kwargs)
        
    torch.load = patched_load
except ImportError:
    pass
# -----------------------------------------

class Transcriber:
    """
    –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–µ—Ä –Ω–∞ –±–∞–∑–µ WhisperX.
    
    –≠—Ç–∞–ø—ã:
    1. Transcribe (Faster-Whisper) - —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞.
    2. Alignment (Wav2Vec2) - –ø–æ—Å–∏–º–≤–æ–ª—å–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Ç–∞–π–º–∏–Ω–≥–æ–≤.
    3. Diarization (PyAnnote) - —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∏–∫–µ—Ä–æ–≤.
    4. Smart Split - –Ω–∞—Ä–µ–∑–∫–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –¥—É–±–ª—è–∂–∞.
    
    –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
    - –ü–æ–ª–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ Apple Silicon (M1/M2/M3) –±–µ–∑ –∫—Ä–∞—à–µ–π.
    - –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ (–≤—ã–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –º–µ–∂–¥—É —à–∞–≥–∞–º–∏).
    """
    
    def __init__(
        self,
        model_size: str = "large-v3",
        hf_token: Optional[str] = None,
        progress_callback: Optional[Callable[[str], None]] = None,
        should_stop_callback: Optional[Callable[[], bool]] = None
    ):
        self.model_size = model_size
        self.hf_token = hf_token or os.getenv("HF_TOKEN")
        self.progress_callback = progress_callback
        self.should_stop_callback = should_stop_callback
        
        # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (Mac vs Windows)
        self.device, self.compute_type = self._detect_environment()
        
    def _log(self, msg: str):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ UI –∏ –∫–æ–Ω—Å–æ–ª—å"""
        print(msg)  # –í –∫–æ–Ω—Å–æ–ª—å
        if self.progress_callback:
            self.progress_callback(msg) # –í UI

    def _detect_environment(self):
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∂–µ–ª–µ–∑–æ.
        –ù–∞ Mac (Darwin) –∏—Å–ø–æ–ª—å–∑—É–µ–º float32 –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ alignment.
        float16 –∫—Ä–∞—à–∏—Ç—Å—è –Ω–∞ Mac CPU, –Ω–æ float32 —Ä–∞–±–æ—Ç–∞–µ—Ç –∏ –Ω–∞–º–Ω–æ–≥–æ —Ç–æ—á–Ω–µ–µ int8.
        """
        system = platform.system()
        
        if system == "Darwin":
            self._log("üçè –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ macOS (Apple Silicon).")
            self._log("‚öôÔ∏è –†–µ–∂–∏–º: CPU / float32 (–í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –¥–ª—è Alignment)")
            # float32 —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ Mac –∏ –¥–∞–µ—Ç –Ω–∞–º–Ω–æ–≥–æ –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ —Ç–∞–π–º–∏–Ω–≥–∏ —á–µ–º int8
            # –≠—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã alignment –º–æ–¥–µ–ª–∏
            return "cpu", "float32"
        
        if torch.cuda.is_available():
            self._log("üü¢ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ NVIDIA GPU (CUDA).")
            return "cuda", "float16"
            
        self._log("‚ö†Ô∏è GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU.")
        return "cpu", "float32"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º float32 –∏ –¥–ª—è –¥—Ä—É–≥–∏—Ö CPU —Å–∏—Å—Ç–µ–º

    def _cleanup_memory(self):
        """–û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –æ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π"""
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            torch.mps.empty_cache()
    
    def _normalize_language_code(self, lang_code: str) -> str:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∫–æ–¥ —è–∑—ã–∫–∞ –¥–ª—è WhisperX alignment.
        Whisper –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å 'ru', –Ω–æ alignment –º–æ–∂–µ—Ç —Ç—Ä–µ–±–æ–≤–∞—Ç—å —Ç–æ—á–Ω–æ–≥–æ –∫–æ–¥–∞.
        """
        # –ú–∞–ø–ø–∏–Ω–≥ —è–∑—ã–∫–æ–≤ –¥–ª—è alignment –º–æ–¥–µ–ª–µ–π
        lang_map = {
            'ru': 'ru',  # –†—É—Å—Å–∫–∏–π
            'en': 'en',  # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π
            'es': 'es',  # –ò—Å–ø–∞–Ω—Å–∫–∏–π
            'fr': 'fr',  # –§—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π
            'de': 'de',  # –ù–µ–º–µ—Ü–∫–∏–π
            'it': 'it',  # –ò—Ç–∞–ª—å—è–Ω—Å–∫–∏–π
            'pt': 'pt',  # –ü–æ—Ä—Ç—É–≥–∞–ª—å—Å–∫–∏–π
            'pl': 'pl',  # –ü–æ–ª—å—Å–∫–∏–π
            'tr': 'tr',  # –¢—É—Ä–µ—Ü–∫–∏–π
            'nl': 'nl',  # –ì–æ–ª–ª–∞–Ω–¥—Å–∫–∏–π
            'cs': 'cs',  # –ß–µ—à—Å–∫–∏–π
            'ar': 'ar',  # –ê—Ä–∞–±—Å–∫–∏–π
            'zh': 'zh',  # –ö–∏—Ç–∞–π—Å–∫–∏–π
            'ja': 'ja',  # –Ø–ø–æ–Ω—Å–∫–∏–π
            'ko': 'ko',  # –ö–æ—Ä–µ–π—Å–∫–∏–π
        }
        
        # –ï—Å–ª–∏ —è–∑—ã–∫ –µ—Å—Ç—å –≤ –º–∞–ø–ø–∏–Ω–≥–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ–≥–æ
        if lang_code in lang_map:
            return lang_map[lang_code]
        
        # –ï—Å–ª–∏ —è–∑—ã–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º –ø–µ—Ä–≤—ã–µ 2 —Å–∏–º–≤–æ–ª–∞ (–¥–ª—è —Å–ª—É—á–∞–µ–≤ —Ç–∏–ø–∞ 'ru-RU')
        lang_base = lang_code.split('-')[0].split('_')[0].lower()
        if lang_base in lang_map:
            return lang_map[lang_base]
        
        # Fallback: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å, –Ω–æ –ª–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
        self._log(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–æ–¥ —è–∑—ã–∫–∞ –¥–ª—è alignment: {lang_code}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å")
        return lang_code

    def transcribe_full(
        self,
        audio_path: str,
        language: Optional[str] = None,
        batch_size: int = 4,  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —Å float32 –Ω–∞ Mac
        min_speakers: Optional[int] = None,
        max_speakers: Optional[int] = None,
        num_speakers: Optional[int] = None
    ) -> Dict:
        """
        –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞.
        """
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_path}")

        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤–Ω—É—Ç—Ä–∏ –º–µ—Ç–æ–¥–∞, —á—Ç–æ–±—ã –Ω–µ –≥—Ä—É–∑–∏—Ç—å –ø–∞–º—è—Ç—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
        import whisperx

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º
            if self.should_stop_callback and self.should_stop_callback():
                self._log("‚èπÔ∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                raise InterruptedError("Processing stopped by user")
            
            # --- –®–ê–ì 1: –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–Ø ---
            self._log(f"\nüéß –®–∞–≥ 1/4: –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è ({self.model_size})...")
            
            model = whisperx.load_model(
                self.model_size,
                device=self.device,
                compute_type=self.compute_type,
                language=language
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–µ—Ä–µ–¥ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π
            if self.should_stop_callback and self.should_stop_callback():
                del model
                self._cleanup_memory()
                self._log("‚èπÔ∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                raise InterruptedError("Processing stopped by user")
            
            # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ç–æ—á–Ω—ã—Ö —Ç–∞–π–º–∏–Ω–≥–æ–≤
            # chunk_size=10: –∑–∞—Å—Ç–∞–≤–ª—è–µ—Ç Whisper —á–∞—â–µ —Å–±—Ä–∞—Å—ã–≤–∞—Ç—å —Ç–∞–π–º–∏–Ω–≥–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 30)
            # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç —Å–∂–∞—Ç–∏–µ –¥–ª–∏–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏ —É–ª—É—á—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å alignment
            self._log(f"‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: batch_size={batch_size}, chunk_size=10 (—Ç–æ—á–Ω—ã–µ —Ç–∞–π–º–∏–Ω–≥–∏)")
            
            result = model.transcribe(
                audio_path,
                batch_size=batch_size,
                chunk_size=10  # –ö—Ä–∏—Ç–∏—á–Ω–æ: –º–µ–Ω—å—à–∏–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ = –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ —Ç–∞–π–º–∏–Ω–≥–∏ –¥–ª—è alignment
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
            if self.should_stop_callback and self.should_stop_callback():
                del model
                self._cleanup_memory()
                self._log("‚èπÔ∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                raise InterruptedError("Processing stopped by user")
            
            detected_lang = result["language"]
            self._log(f"üåç –Ø–∑—ã–∫ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞: {detected_lang}")
            
            # –ß–∏—Å—Ç–∏–º –ø–∞–º—è—Ç—å
            del model
            self._cleanup_memory()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–µ—Ä–µ–¥ alignment
            if self.should_stop_callback and self.should_stop_callback():
                self._log("‚èπÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                raise InterruptedError("Processing stopped by user")
            
            # --- –®–ê–ì 2: –í–´–†–ê–í–ù–ò–í–ê–ù–ò–ï (Alignment) ---
            self._log(f"\nüìê –®–∞–≥ 2/4: –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Ç–∞–π–º–∏–Ω–≥–æ–≤...")
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–æ–¥ —è–∑—ã–∫–∞ –¥–ª—è alignment
            align_lang = self._normalize_language_code(detected_lang)
            self._log(f"üî§ –ö–æ–¥ —è–∑—ã–∫–∞ –¥–ª—è alignment: {align_lang} (–∏—Å—Ö–æ–¥–Ω—ã–π: {detected_lang})")
            
            alignment_success = False
            try:
                self._log(f"üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –¥–ª—è —è–∑—ã–∫–∞: {align_lang}...")
                align_model, align_metadata = whisperx.load_align_model(
                    language_code=align_lang,
                    device=self.device
                )
                self._log(f"‚úÖ –ú–æ–¥–µ–ª—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                
                self._log(f"üîÑ –ó–∞–ø—É—Å–∫ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è...")
                result = whisperx.align(
                    result["segments"],
                    align_model,
                    align_metadata,
                    audio_path,
                    device=self.device,
                    return_char_alignments=False
                )
                
                # –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –û–¢–õ–ê–î–û–ß–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï
                if result.get("segments") and len(result["segments"]) > 0:
                    seg0 = result["segments"][0]
                    print(f"\n{'='*60}")
                    print(f"DEBUG SEGMENT 0 KEYS: {list(seg0.keys())}")
                    print(f"DEBUG SEGMENT 0 HAS 'words': {'words' in seg0}")
                    if "words" in seg0:
                        words_count = len(seg0.get("words", []))
                        print(f"DEBUG SEGMENT 0 WORDS COUNT: {words_count}")
                        if words_count > 0:
                            first_word = seg0["words"][0]
                            print(f"DEBUG FIRST WORD: {first_word}")
                            print(f"DEBUG FIRST WORD KEYS: {list(first_word.keys())}")
                        else:
                            print(f"DEBUG SEGMENT 0 WORDS: [] (–ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫)")
                    else:
                        print(f"DEBUG SEGMENT 0 WORDS: NO_WORDS_FOUND")
                    print(f"DEBUG SEGMENT 0 TEXT: {seg0.get('text', 'NO_TEXT')[:100]}")
                    print(f"DEBUG SEGMENT 0 TIME: {seg0.get('start', 'NO_START')} -> {seg0.get('end', 'NO_END')}")
                    print(f"{'='*60}\n")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã
                    segments_with_words = sum(1 for s in result["segments"] if "words" in s and len(s.get("words", [])) > 0)
                    total_segments = len(result["segments"])
                    self._log(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è: {segments_with_words}/{total_segments} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å–æ–¥–µ—Ä–∂–∞—Ç —Å–ª–æ–≤–∞")
                    
                    if segments_with_words == 0:
                        self._log(f"‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –Ω–µ –¥–æ–±–∞–≤–∏–ª–æ —Å–ª–æ–≤–∞ –Ω–∏ –≤ –æ–¥–∏–Ω —Å–µ–≥–º–µ–Ω—Ç!")
                        self._log(f"‚ö†Ô∏è –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ alignment –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–¥ —è–∑—ã–∫–∞ –∏ –º–æ–¥–µ–ª—å.")
                else:
                    print(f"\n{'='*60}")
                    print(f"DEBUG: result['segments'] –ø—É—Å—Ç –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç!")
                    print(f"DEBUG result keys: {list(result.keys())}")
                    print(f"{'='*60}\n")
                
                alignment_success = True
                del align_model
                del align_metadata
                
            except FileNotFoundError as e:
                self._log(f"‚ùå –û—à–∏–±–∫–∞: –ú–æ–¥–µ–ª—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –¥–ª—è —è–∑—ã–∫–∞ '{align_lang}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                self._log(f"üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —è–∑—ã–∫ –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π")
                self._log(f"üìã –î–µ—Ç–∞–ª–∏: {str(e)}")
            except MemoryError as e:
                self._log(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞–º—è—Ç–∏ –ø—Ä–∏ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–∏: {e}")
                self._log(f"üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–º–µ–Ω—å—à–∏—Ç—å batch_size –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–Ω—å—à—É—é –º–æ–¥–µ–ª—å")
            except Exception as e:
                error_type = type(e).__name__
                self._log(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è ({error_type}): {str(e)}")
                self._log(f"üìã Traceback:")
                self._log(traceback.format_exc())
                self._log(f"‚ö†Ô∏è –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è (—Ç–∞–π–º–∏–Ω–≥–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ—Ç–æ—á–Ω—ã–º–∏)")
            
            if not alignment_success:
                self._log(f"‚ö†Ô∏è –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ. –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –±—É–¥–µ—Ç –±–∞–∑–æ–≤–∞—è (–±–µ–∑ —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)")
            
            self._cleanup_memory()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–µ—Ä–µ–¥ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–µ–π
            if self.should_stop_callback and self.should_stop_callback():
                self._log("‚èπÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                raise InterruptedError("Processing stopped by user")
            
            # --- –®–ê–ì 3: –î–ò–ê–†–ò–ó–ê–¶–ò–Ø ---
            self._log(f"\nüë• –®–∞–≥ 3/4: –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è (PyAnnote)...")
            
            diarize_segments = None
            if self.hf_token:
                from whisperx import diarize
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏
                diarize_model = diarize.DiarizationPipeline(
                    use_auth_token=self.hf_token,
                    device=self.device
                )
                
                diarize_segments = diarize_model(
                    audio_path,
                    min_speakers=min_speakers,
                    max_speakers=max_speakers,
                    num_speakers=num_speakers
                )
                
                del diarize_model
                self._cleanup_memory()
                
                # --- –®–ê–ì 4: –°–ë–û–†–ö–ê –ò –£–ú–ù–ê–Ø –ù–ê–†–ï–ó–ö–ê ---
                self._log(f"\nüîó –®–∞–≥ 4/4: –°–±–æ—Ä–∫–∞ –∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è...")
                
                # –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º —Å–ø–∏–∫–µ—Ä–æ–≤ —Å–ª–æ–≤–∞–º
                result = diarize.assign_word_speakers(
                    diarize_segments,
                    result
                )
            else:
                self._log("‚ö†Ô∏è HF Token –Ω–µ –Ω–∞–π–¥–µ–Ω. –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–∞ (–±—É–¥–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç).")

            # –ó–∞–ø—É—Å–∫–∞–µ–º –†–ê–ó–ë–ò–ï–ù–ò–ï –ü–û –ü–†–ï–î–õ–û–ñ–ï–ù–ò–Ø–ú (Sentence-Level Splitter)
            # –†–µ–∫–æ–Ω—Å—Ç—Ä—É–∏—Ä—É–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã —Å—Ç—Ä–æ–≥–æ –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–≤
            # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç LLM –≤–∏–¥–µ—Ç—å –ø–µ—Ä–µ—Ö–æ–¥—ã –º–µ–∂–¥—É —Å–ø–∏–∫–µ—Ä–∞–º–∏ –¥–∞–∂–µ –≤ –±—ã—Å—Ç—Ä–æ–º –¥–∏–∞–ª–æ–≥–µ
            # LLM –≤ corrector.py –≤—ã—Å—Ç—É–ø–∏—Ç "Script Editor" –∏ –∏—Å–ø—Ä–∞–≤–∏—Ç —Å–ø–∏–∫–µ—Ä–æ–≤ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
            final_segments = self._smart_sentence_split(result["segments"])
            
            # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            speakers_found = set(s.get("speaker") for s in final_segments if "speaker" in s)
            self._log(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –°–ø–∏–∫–µ—Ä–æ–≤: {len(speakers_found)}. –°–µ–≥–º–µ–Ω—Ç–æ–≤: {len(final_segments)}")
            
            return {
                "segments": final_segments,
                "language": detected_lang
            }

        except InterruptedError:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
            self._log("‚èπÔ∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            return {"segments": [], "language": "en", "stopped": True}
        except Exception as e:
            self._log(f"‚ùå –û–®–ò–ë–ö–ê: {e}")
            self._log(traceback.format_exc())
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, —á—Ç–æ–±—ã –ø—Ä–æ–≥—Ä–∞–º–º–∞ –Ω–µ —É–ø–∞–ª–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é
            return {"segments": [], "language": "en", "error": str(e)}
        finally:
            self._cleanup_memory()

    def _smart_sentence_split(self, whisperx_segments: List[Dict]) -> List[Dict]:
        """
        –†–ê–ó–ë–ò–ï–ù–ò–ï –ü–û –ü–†–ï–î–õ–û–ñ–ï–ù–ò–Ø–ú (Sentence-Level Splitter)
        
        –†–µ–∫–æ–Ω—Å—Ç—Ä—É–∏—Ä—É–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã —Å—Ç—Ä–æ–≥–æ –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–ª–æ–≤.
        –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç LLM –≤–∏–¥–µ—Ç—å –ø–µ—Ä–µ—Ö–æ–¥—ã –º–µ–∂–¥—É —Å–ø–∏–∫–µ—Ä–∞–º–∏ –¥–∞–∂–µ –≤ –±—ã—Å—Ç—Ä–æ–º –¥–∏–∞–ª–æ–≥–µ.
        
        –ê–ª–≥–æ—Ä–∏—Ç–º:
        1. FLATTEN: –ò–∑–≤–ª–µ–∫–∞–µ—Ç –í–°–ï —Å–ª–æ–≤–∞ –∏–∑ –í–°–ï–• —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫
        2. RECONSTRUCT: –ò—Ç–µ—Ä–∏—Ä—É–µ—Ç—Å—è –ø–æ —Å–ª–æ–≤–∞–º –∏ —Å—Ç—Ä–æ–∏—Ç —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
        3. TRIGGER SPLIT: –†–∞–∑–±–∏–≤–∞–µ—Ç –ø—Ä–∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ [.!?]
        4. SAFETY SPLIT: –†–∞–∑–±–∏–≤–∞–µ—Ç –µ—Å–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ > 3.0 —Å–µ–∫ –±–µ–∑ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
        5. GAP SPLIT: –†–∞–∑–±–∏–≤–∞–µ—Ç –ø—Ä–∏ –ø–∞—É–∑–µ > 0.5 —Å–µ–∫ –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏
        
        –†–µ–∑—É–ª—å—Ç–∞—Ç: –ú–Ω–æ–≥–æ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        –ü—Ä–∏–º–µ—Ä: [20s-24s]: "...ID." –∏ [24s-25s]: "Yes." –≤–º–µ—Å—Ç–æ –æ–¥–Ω–æ–≥–æ –±–ª–æ–∫–∞
        """
        # –û–¢–õ–ê–î–ö–ê: –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        print(f"\n{'='*60}")
        print(f"DEBUG Sentence Splitter: –ø–æ–ª—É—á–µ–Ω–æ {len(whisperx_segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        if whisperx_segments:
            print(f"DEBUG –ü–µ—Ä–≤—ã–π —Å–µ–≥–º–µ–Ω—Ç keys: {list(whisperx_segments[0].keys())}")
            if "words" in whisperx_segments[0]:
                words_in_first = len(whisperx_segments[0].get("words", []))
                print(f"DEBUG –°–ª–æ–≤ –≤ –ø–µ—Ä–≤–æ–º —Å–µ–≥–º–µ–Ω—Ç–µ: {words_in_first}")
        print(f"{'='*60}\n")
        
        # –®–ê–ì 1: FLATTEN - –ò–∑–≤–ª–µ–∫–∞–µ–º –í–°–ï —Å–ª–æ–≤–∞ –∏–∑ –í–°–ï–• —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫
        all_words = []
        segments_with_words = 0
        
        for seg in whisperx_segments:
            if "words" in seg and seg["words"]:
                segments_with_words += 1
                seg_speaker = seg.get("speaker", "SPEAKER_UNKNOWN")
                
                for word in seg["words"]:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–ª–æ–≤–æ –∏–º–µ–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è
                    if not isinstance(word, dict) or "word" not in word:
                        continue
                    
                    # –ù–∞—Å–ª–µ–¥—É–µ–º —Å–ø–∏–∫–µ—Ä–∞ —Å–µ–≥–º–µ–Ω—Ç–∞, –µ—Å–ª–∏ —É —Å–ª–æ–≤–∞ –Ω–µ—Ç —Å–≤–æ–µ–≥–æ
                    if "speaker" not in word:
                        word["speaker"] = seg_speaker
                    
                    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –µ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: float())
                    word_start = word.get("start")
                    word_end = word.get("end")
                    
                    if word_start is None or word_end is None:
                        # –ü—Ä–æ–±—É–µ–º –≤–∑—è—Ç—å –∏–∑ —Å–µ–≥–º–µ–Ω—Ç–∞
                        word_start = float(seg.get("start", 0)) if "start" in seg else 0.0
                        word_end = float(seg.get("end", 0)) if "end" in seg else 0.0
                    
                    word["start"] = float(word_start)
                    word["end"] = float(word_end)
                    
                    all_words.append(word)
        
        print(f"DEBUG: –°–æ–±—Ä–∞–Ω–æ {len(all_words)} —Å–ª–æ–≤ –∏–∑ {segments_with_words} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        
        # –ï—Å–ª–∏ —Å–ª–æ–≤ –Ω–µ—Ç (Alignment –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª), –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        if not all_words:
            self._log(f"‚ö†Ô∏è –†–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ: —Å–ª–æ–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã (alignment –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª)")
            self._log(f"üìù –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è")
            return self._format_basic(whisperx_segments)

        # –®–ê–ì 2: RECONSTRUCT - –ò—Ç–µ—Ä–∏—Ä—É–µ–º—Å—è –ø–æ —Å–ª–æ–≤–∞–º –∏ —Å—Ç—Ä–æ–∏–º —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
        reconstructed_segments = []
        current_words = []
        current_speaker = None
        sentence_start_time = None  # –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        
        for i, word in enumerate(all_words):
            text = word.get("word", "").strip()
            if not text:
                continue
            
            speaker = word.get("speaker", "SPEAKER_UNKNOWN")
            word_start = float(word.get("start", 0))
            word_end = float(word.get("end", 0))
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ
            if sentence_start_time is None:
                sentence_start_time = word_start
                current_speaker = speaker
            
            # –°–º–µ–Ω–∞ —Å–ø–∏–∫–µ—Ä–∞ = –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞–∑—Ä—ã–≤ (–Ω–æ–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)
            if speaker != current_speaker:
                if current_words:
                    reconstructed_segments.append(self._make_segment(current_words, current_speaker))
                    current_words = []
                    sentence_start_time = word_start
                current_speaker = speaker
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–æ –≤ —Ç–µ–∫—É—â–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
            current_words.append(word)
            
            # –ü–†–û–í–ï–†–ö–ê –£–°–õ–û–í–ò–ô –†–ê–ó–ë–ò–ï–ù–ò–Ø (TRIGGER SPLIT):
            should_split = False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–µ–¥—É—é—â–µ–µ —Å–ª–æ–≤–æ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–¥–ª—è GAP SPLIT)
            has_next_word = i < len(all_words) - 1
            
            # –£—Å–ª–æ–≤–∏–µ 1: –ü—É–Ω–∫—Ç—É–∞—Ü–∏—è [.!?] - –ê–ì–†–ï–°–°–ò–í–ù–û–ï –†–ê–ó–ë–ò–ï–ù–ò–ï
            # –í–°–ï–ì–î–ê —Ä–∞–∑–±–∏–≤–∞–µ–º –ø—Ä–∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏, –¥–∞–∂–µ –µ—Å–ª–∏ —Å–ª–µ–¥—É—é—â–µ–µ —Å–ª–æ–≤–æ - —á–∏—Å–ª–æ
            # –õ—É—á—à–µ "over-split" (LLM —Å–º–æ–∂–µ—Ç –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å), —á–µ–º "under-split" (–∑–∞–±–ª–æ–∫–∏—Ä—É–µ—Ç —Ä–∞–∑–Ω—ã—Ö —Å–ø–∏–∫–µ—Ä–æ–≤)
            has_punctuation = bool(re.search(r'[.!?]+$', text))
            if has_punctuation:
                should_split = True  # –í–°–ï–ì–î–ê —Ä–∞–∑–±–∏–≤–∞–µ–º –ø—Ä–∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
            
            # –£—Å–ª–æ–≤–∏–µ 2: SAFETY SPLIT - –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è > 4.0 —Å–µ–∫ –±–µ–∑ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
            if not should_split and sentence_start_time is not None:
                sentence_duration = word_end - sentence_start_time
                if sentence_duration > 4.0:
                    should_split = True
            
            # –£—Å–ª–æ–≤–∏–µ 3: GAP SPLIT - –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏ > 0.8 —Å–µ–∫
            if not should_split and has_next_word:
                next_word = all_words[i + 1]
                next_start = float(next_word.get("start", word_end))
                pause_duration = next_start - word_end
                if pause_duration > 0.8:
                    should_split = True
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º —Ä–∞–∑–±–∏–µ–Ω–∏–µ (–∑–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)
            if should_split:
                if current_words:
                    reconstructed_segments.append(self._make_segment(current_words, current_speaker))
                    current_words = []
                    # –°–±—Ä–æ—Å –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                    if i < len(all_words) - 1:
                        next_word = all_words[i + 1]
                        sentence_start_time = float(next_word.get("start", word_end))
                    else:
                        sentence_start_time = None

        # –î–æ–±–∞–≤–ª—è–µ–º —Ö–≤–æ—Å—Ç (–ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)
        if current_words:
            reconstructed_segments.append(self._make_segment(current_words, current_speaker))
        
        self._log(f"üìù –†–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º: {len(whisperx_segments)} ‚Üí {len(reconstructed_segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        
        return reconstructed_segments

    def _make_segment(self, words: List[Dict], speaker: str) -> Dict:
        """–°–æ–±–∏—Ä–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç –∏–∑ —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤ (–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: float())"""
        if not words: 
            return {}
        
        start = float(words[0].get("start", 0))
        end = float(words[-1].get("end", 0))
        text = " ".join([w.get("word", "").strip() for w in words])
        
        return {
            "start": start,
            "end": end,
            "text": text.replace("  ", " ").strip(),
            "speaker": speaker
        }

    def _format_basic(self, segments: List[Dict]) -> List[Dict]:
        """Fallback –º–µ—Ç–æ–¥, –µ—Å–ª–∏ –Ω–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ (–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: float())"""
        clean = []
        for seg in segments:
            clean.append({
                "start": float(seg.get("start", 0)),
                "end": float(seg.get("end", 0)),
                "text": seg.get("text", "").strip(),
                "speaker": seg.get("speaker", "SPEAKER_UNKNOWN")
            })
        return clean